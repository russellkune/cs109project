{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression as LogReg\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.cluster import KMeans\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('Reviews.csv')\n",
    "unique_users = reviews.UserId.unique()\n",
    "unique_products = reviews.ProductId.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model:\n",
    "- Simple Averaging: A simple baseline model is to use the average of all other scores of a particular product to predict how a user will rate the product. If there is no other data on the product we guess 3.\n",
    "- Content based recommendation: Given a product, recommend the most similar products based on content of user reviews and summaries for those products. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Simple Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Uses average score to predict how a user will score, for the first 10000 observations\n",
    "def compute_baseline_error():\n",
    "    l1score = []\n",
    "    misclassified = []\n",
    "\n",
    "    for i in  range(10000):\n",
    "        correct = 0 \n",
    "        score = reviews.ix[i,:].Score\n",
    "        product = reviews.ix[i,:].ProductId\n",
    "        ID = reviews.ix[i,:].Id\n",
    "        other_reviews = reviews[(reviews.ProductId == product) & (reviews.Id != ID)].Score.values\n",
    "        if len(other_reviews) == 0:\n",
    "            guess = 3 \n",
    "        else:\n",
    "            guess = other_reviews.mean()\n",
    "        \n",
    "        offby = guess - score\n",
    "        if int(guess+0.5) == int(score):\n",
    "            correct = 1\n",
    "        \n",
    "        l1score.append(offby)\n",
    "        misclassified.append(correct)\n",
    "    return l1score,misclassified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323.726979971\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "start = time.time()\n",
    "l,m = compute_baseline_error()\n",
    "end = time.time()\n",
    "print end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction Correctly Classified:  0.3287\n"
     ]
    }
   ],
   "source": [
    "print \"Fraction Correctly Classified: \", sum(m)/float(len(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also relabel good (4,5) or bad (1,2,3) scores as 1 and 0 and see how well this does, guessing 1 if there's no data (justify later but people are probably more likely to give positive reviews than negative ones). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modified_baseline_error():\n",
    "    misclassified = []\n",
    "\n",
    "    for i in  range(10000):\n",
    "        correct = 0 \n",
    "        score = reviews.ix[i,:].Score\n",
    "        product = reviews.ix[i,:].ProductId\n",
    "        ID = reviews.ix[i,:].Id\n",
    "        other_reviews = reviews[(reviews.ProductId == product) & (reviews.Id != ID)].Score.values\n",
    "        if len(other_reviews) == 0:\n",
    "            guess = 5 \n",
    "        else:\n",
    "            guess = other_reviews.mean()\n",
    "        \n",
    "        if guess >= 3.5:\n",
    "            new_guess = 1\n",
    "        else:\n",
    "            new_guess = 0\n",
    "        if score >=3.5:\n",
    "            new_score = 1\n",
    "        else:\n",
    "            new_score = 0\n",
    "                \n",
    "        if new_guess == new_score:\n",
    "            misclassified.append(1)\n",
    "        else:\n",
    "            misclassified.append(0)\n",
    "    return misclassified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312.308862925\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "start = time.time()\n",
    "m = modified_baseline_error()\n",
    "end = time.time()\n",
    "print end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction Correctly Classified:  0.7487\n"
     ]
    }
   ],
   "source": [
    "print 'Fraction Correctly Classified: ', sum(m)/float(len(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So given a product is rated an average of 3.5 or above, there is a .75 chance that the user rates the product as 4 or 5. This can be modified to recommend the products with highest average rating to all users. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Content Based Recommendation\n",
    "Given that a user is viewing/ purchased a particular item, recommend items that are very similar to that item based on the summary and content of reviews.\n",
    "- **Input**: Product ID (viewed/purchased item) , Similarity Matrix based on Cosine similarity score of Term Frequency Inverse Document Frequency Vectors\n",
    "- **Output**: List of Product IDs of Similar Products and associated similarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Useful Packages\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.cluster.vq import vq,kmeans,whiten\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I created a new dataframe with unique products and their associated text by appending all reviews/ summaries associated with a particular product together. This is slow, so I only used the first 1000 products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.7132220268\n"
     ]
    }
   ],
   "source": [
    "#whole thing takes a long time(>30minutes), use first 1000 products\n",
    "start = time.time()\n",
    "unique_prod_reviews = map(lambda x: to_words(x),unique_products[0:1000])\n",
    "end = time.time()\n",
    "print end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>[I have bought several of the Vitality canned ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>[Product arrived labeled as Jumbo Salted Peanu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>[This is a confection that has been around a f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>[If you are looking for the secret ingredient ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>[Great taffy at a great price.  There was a wi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ProductId                                               Text\n",
       "0  B001E4KFG0  [I have bought several of the Vitality canned ...\n",
       "1  B00813GRG4  [Product arrived labeled as Jumbo Salted Peanu...\n",
       "2  B000LQOCH0  [This is a confection that has been around a f...\n",
       "3  B000UA0QIQ  [If you are looking for the secret ingredient ...\n",
       "4  B006K2ZZ7K  [Great taffy at a great price.  There was a wi..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the first 5 entries of the product DF\n",
    "product_df = pd.DataFrame()\n",
    "product_df['ProductId'] = unique_products[0:1000]\n",
    "product_df['Text'] = unique_prod_reviews\n",
    "product_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use SKLearn's implementation of TF-IDF to get a sparse vector for each item , then use linear-kernel to get cosine similary scores between items and store these in a 1000x1000 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array(unique_prod_reviews)\n",
    "a = a.reshape(len(a),)\n",
    "tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 3), min_df=0, stop_words='english')\n",
    "tfidf_matrix = tf.fit_transform(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00,   5.36110174e-03,   0.00000000e+00, ...,\n",
       "          8.28603989e-03,   5.19533133e-03,   5.02833995e-03],\n",
       "       [  5.36110174e-03,   1.00000000e+00,   0.00000000e+00, ...,\n",
       "          5.29899866e-03,   0.00000000e+00,   1.78627910e-03],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       ..., \n",
       "       [  8.28603989e-03,   5.29899866e-03,   0.00000000e+00, ...,\n",
       "          1.00000000e+00,   8.30201976e-03,   7.89411311e-04],\n",
       "       [  5.19533133e-03,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          8.30201976e-03,   1.00000000e+00,   4.70532436e-03],\n",
       "       [  5.02833995e-03,   1.78627910e-03,   0.00000000e+00, ...,\n",
       "          7.89411311e-04,   4.70532436e-03,   1.00000000e+00]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix.toarray()\n",
    "cosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "cosine_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is the TF-IDF Matrix for the first 1000 products. Below I wrote a function to return 8 most similar items given a product ID and similarity matrix as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#takes a product name in the unique products data and returns the 8 most similar products\n",
    "#input: Product ID, Product Dataframe, Similarity Matrix\n",
    "#output: Array of 8 nearest items in the database using cosine similarity\n",
    "\n",
    "def return_nearest(product,cosine_similarities,product_df):\n",
    "    idx = product_df[product_df.ProductId == product].index[0]\n",
    "    similar_indices = cosine_similarities[idx].argsort()[:-10:-1]\n",
    "    similar_items = [(cosine_similarities[idx][i], product_df['ProductId'][i]) for i in similar_indices]\n",
    "    return similar_items[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.060071873611170931, 'B000CMFMG8'),\n",
       " (0.052140838382313696, 'B0047LRBX2'),\n",
       " (0.043432096349825311, 'B001EO6BCC'),\n",
       " (0.037325003722012799, 'B000G6RPMY'),\n",
       " (0.026276191344016604, 'B001FA1L7U'),\n",
       " (0.025318462964514555, 'B004AVYUOW'),\n",
       " (0.025057186536542934, 'B001HOUGFC'),\n",
       " (0.023818763987623219, 'B000YT5DBS')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_nearest('B00813GRG4',cosine_similarities,product_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Searching the product IDs on Amazon, the input product is a brand of peanut, and most of the recommended items are different types of peanuts. The downside of this approach is that the items recommended are too similar to the product that the user viewed/purchased, so it is unlikely that the recommender will generate much revenue that the companies would not have already received. \n",
    "- For the simple averaging recommender, very highly rated items are recommended, but they aren't related to what the user is viewing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stuff after this is useless (ignore):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#can't train on too large of a subset of the data on my computer, use first 10000\n",
    "\n",
    "reviews1 = reviews.ix[0:10000].dropna()\n",
    "vectorizer = CountVectorizer(stop_words= 'english', min_df=4)\n",
    "text = reviews1['Text'].values + ' ' + reviews1['Summary'].values\n",
    "vectorizer.fit(text)\n",
    "x = vectorizer.fit_transform(text)\n",
    "x = x.toarray( )\n",
    "features = vectorizer.get_feature_names() \n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#input: product ID\n",
    "#output: sparse vector based on vectorizer\n",
    "\n",
    "def to_vector(product_id):\n",
    "    temp = reviews[reviews.ProductId == product_id]\n",
    "    text = list(temp['Text'].values + ' ' + temp['Summary'].values)\n",
    "    new_string = np.array([''.join(text)]).reshape(1,)\n",
    "    return vectorizer.transform(new_string).toarray()\n",
    "\n",
    "def to_words(product_id):\n",
    "    temp = reviews[reviews.ProductId == product_id]\n",
    "    text = list(temp['Text'].astype(str).values + ' ' + temp['Summary'].astype(str).values)\n",
    "    return np.array([''.join(text)]).reshape(1,)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def similarity(product1,product2):\n",
    "    vector1 = vectorizer.transform(product1)\n",
    "    vector2 = vectorizer.transform(product2)\n",
    "    #do some cosine thing -- > closer to 1 is closer in distance\n",
    "    #might need to transform to lower dimensional space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#One approach to reduce dimensionality is k means clustering, similarity can be computed through\n",
    "#distance between histograms\n",
    "\n",
    "def make_cluster(k,vector):\n",
    "    bagofwords= kmeans(vector,n)\n",
    "    return bagofwords[0]\n",
    "def hist(vector,cluster):\n",
    "    p = vq(vector,cluster)\n",
    "    labels = p[0]\n",
    "    hist,bins = np.histogram(labels,bins=np.arange(-.5,200,1))\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Only use the first 1000 products for now - too slow\n",
    "df_products = pd.DataFrame(index = unique_products[0:100], columns = unique_products[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = to_vector(unique_products[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster= make_cluster(50,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10001, 6469)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
