{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression as LogReg\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.cluster.vq import vq,kmeans,whiten\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#functions \n",
    "#input: product ID\n",
    "#output: sparse vector based on vectorizer\n",
    "\n",
    "def to_vector(product_id):\n",
    "    temp = reviews[reviews.ProductId == product_id]\n",
    "    text = list(temp['Text'].values + ' ' + temp['Summary'].values)\n",
    "    new_string = np.array([''.join(text)]).reshape(1,)\n",
    "    return vectorizer.transform(new_string).toarray()\n",
    "\n",
    "def to_words(product_id):\n",
    "    temp = reviews[reviews.ProductId == product_id]\n",
    "    text = list(temp['Text'].astype(str).values + ' ' + temp['Summary'].astype(str).values)\n",
    "    return np.array([''.join(text)]).reshape(1,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Unique products and users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('Reviews.csv')\n",
    "unique_users = reviews.UserId.unique()\n",
    "unique_products = reviews.ProductId.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.4949069023\n"
     ]
    }
   ],
   "source": [
    "#whole thing takes a long time(>30minutes), use first 1000 products\n",
    "start = time.time()\n",
    "unique_prod_reviews = map(lambda x: to_words(x),unique_products[0:1000])\n",
    "end = time.time()\n",
    "print end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>[I have bought several of the Vitality canned ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>[Product arrived labeled as Jumbo Salted Peanu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>[This is a confection that has been around a f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>[If you are looking for the secret ingredient ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>[Great taffy at a great price.  There was a wi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ProductId                                               Text\n",
       "0  B001E4KFG0  [I have bought several of the Vitality canned ...\n",
       "1  B00813GRG4  [Product arrived labeled as Jumbo Salted Peanu...\n",
       "2  B000LQOCH0  [This is a confection that has been around a f...\n",
       "3  B000UA0QIQ  [If you are looking for the secret ingredient ...\n",
       "4  B006K2ZZ7K  [Great taffy at a great price.  There was a wi..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the first 5 entries of the product DF\n",
    "product_df = pd.DataFrame()\n",
    "product_df['ProductId'] = unique_products[0:1000]\n",
    "product_df['Text'] = unique_prod_reviews\n",
    "product_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array(unique_prod_reviews)\n",
    "a = a.reshape(len(a),)\n",
    "tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 3), min_df=0, stop_words='english')\n",
    "tfidf_matrix = tf.fit_transform(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00,   5.36110174e-03,   0.00000000e+00, ...,\n",
       "          8.28603989e-03,   5.19533133e-03,   5.02833995e-03],\n",
       "       [  5.36110174e-03,   1.00000000e+00,   0.00000000e+00, ...,\n",
       "          5.29899866e-03,   0.00000000e+00,   1.78627910e-03],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       ..., \n",
       "       [  8.28603989e-03,   5.29899866e-03,   0.00000000e+00, ...,\n",
       "          1.00000000e+00,   8.30201976e-03,   7.89411311e-04],\n",
       "       [  5.19533133e-03,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          8.30201976e-03,   1.00000000e+00,   4.70532436e-03],\n",
       "       [  5.02833995e-03,   1.78627910e-03,   0.00000000e+00, ...,\n",
       "          7.89411311e-04,   4.70532436e-03,   1.00000000e+00]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix.toarray()\n",
    "cosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "cosine_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#takes a product name in the unique products data and returns the 8 most similar products\n",
    "#input: Product ID, Product Dataframe, Similarity Matrix\n",
    "#output: Array of 8 nearest items in the database using cosine similarity\n",
    "\n",
    "def return_nearest(product,cosine_similarities,product_df):\n",
    "    idx = product_df[product_df.ProductId == product].index[0]\n",
    "    similar_indices = cosine_similarities[idx].argsort()[:-10:-1]\n",
    "    similar_items = [(cosine_similarities[idx][i], product_df['ProductId'][i]) for i in similar_indices]\n",
    "    return similar_items[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.060071873611170931, 'B000CMFMG8'),\n",
       " (0.052140838382313696, 'B0047LRBX2'),\n",
       " (0.043432096349825311, 'B001EO6BCC'),\n",
       " (0.037325003722012799, 'B000G6RPMY'),\n",
       " (0.026276191344016604, 'B001FA1L7U'),\n",
       " (0.025318462964514555, 'B004AVYUOW'),\n",
       " (0.025057186536542934, 'B001HOUGFC'),\n",
       " (0.023818763987623219, 'B000YT5DBS')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_nearest('B00813GRG4',cosine_similarities,product_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def number_reviews(users):\n",
    "    number_reviews_ = []\n",
    "    for user in users:\n",
    "        number_reviews_.append(reviews[reviews['UserId'] == user].values.shape[0])\n",
    "    return np.array(number_reviews_)\n",
    "        \n",
    "start = time.time()    \n",
    "number_reviews_1000 = number_reviews(unique_users[0:1000])\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1   1   3   3   2   1   2   1   2   4   4  12   2  20 201   1   2   1\n",
      "  49   2   1   2   2   4   2   3   2   1   1   1   2  17   4   1   4   3\n",
      "   1   2   6  10   1   1   6  88  12 133   1  14   3   2   2   9   2   2\n",
      "   2   1   1   1   3   1   1   1   1   1   1   1   2   2   3   5   1   3\n",
      "  21   1   4  13  16   1  17   1   1   3   2   4   1   1   2   1   1   1\n",
      "   1   1   2   1   1   9   1   1   1  12   8  18   8  11   7   7   2   4\n",
      " 389   2   4   4   4   4   4   1   1   8   5   5   4   4   9   4   6   4\n",
      "   1  10   1   1   1   3   3  15   3  10   1   1   1   1  75   6 256  27\n",
      "   1   1   1   2   4   2   1   1   1   5   1   5   3  47   4   1   1   1\n",
      "  15   1   4   1   1   3   3   3   1   2   1   2   9   7  33  23   1  22\n",
      "   1   7   1   3   1 140   1   1   1   1  49   1   3   8   1   2   1   1\n",
      "   2   1   3   1   1   1   1   1   1   9   1   1  10   2   8   1   1   3\n",
      "  59   1   2   1   3   2   1   2   9   1   1   1   1   1  99   1   1   4\n",
      "   8   1   6  42  10   1   2   1   1   2   5   1   1   1   1   5   2   1\n",
      "   1   4   2   1   1   4   1   2   1   1   1  11   1  29   1  11   1   1\n",
      "   1  68   1   1   1   1   1   2   1   1  10   2   4  48  44   1   1   1\n",
      "   2  25   2   1   6   1   1   2   1   2   1   2   1   4   2  38   1   3\n",
      "  21   2   3   2   1   3   1   1   1   1   1   2   1   1   1   1   8   1\n",
      "   2   2   1  16   2   1   1   1   2   2   1   1  19   1   1   1   1   1\n",
      "   1   1   1   1   2   1   1   1   1   1   1   2   4   1  28   1   4   3\n",
      "   7  14   1   1   3   3   2 448  96   2  10   7   3   1   1   1   2   1\n",
      "   1   1   1 114   1   1   3   1   7   5   3   1   8   1   6   6   4   3\n",
      " 123   1   2   1   7   1   3  42   1   4   1   1   1   1   1   3  12   1\n",
      "   2   6   6   6 107   4  44  49  16  32  17  15  16 111  16  61  28  43\n",
      "  17  16  36  17  27  14 105  39  18  48  14  20  14  14  14  14  16  14\n",
      "  14  14  14  14  41  14  60  14  30  25 178  14  15  22 162  14  34  27\n",
      "  14  14  14  15  38  14  14  14  22  14  25  72  14  36  14  15  16  15\n",
      "  16  15  19  14  14  14  14  43  14  14  30  15  14  23  29  23  28  14\n",
      "  14  61  14  15  22  18  37  40  16 105  14  36  14  16 162  40  14  15\n",
      "  19  21  14  15  14  14  94 110  16  30  14  14  14  17  16  15  20  30\n",
      "  14  16  14  26  21  17  17  14  14  14  73  14  14 125  16  14  14  49\n",
      "  14  15  14  15  14  92  14  16  82  18  14  14  14  16  26  14  75 176\n",
      "  98  16  14  14  14  15  14  14  17  14  14  15  39  14  16  83  14 155\n",
      "  15  19  21  31  15  14  27  14  14  22  29  63  35  22  14  14  14  14\n",
      "  63  14  16  14  18  14  15   2   2   1   2  13   1   1   3   1   1   4\n",
      "  23  52  15   1   1   1   6   3   3   1   1   3   4   1   3   2   8  10\n",
      "   2   2   1   1   8  12  19   9  15   8   9  10  10   9   8 151   8  12\n",
      " 114   9  17  12   8   8   8   9   8  11   8   8   8  14   8  11  16   8\n",
      "   8   8   8   8   9   8   8  24  21  38   8   8   8   8   8  14   8   8\n",
      "   1   1   2   2   1   1   1   1   1   1   2  21   1  13   2   1   1   1\n",
      "   2  12  20  42   2   1   1   1   1   1   4   5   1   1   1   1 104   1\n",
      "   5   5  16   5  13   5   1   2   8   1   1   1   1   1   1   2   1   3\n",
      "   2 118   2   2   2   2  29   2   2   1   1   1   1   2  17   2   3   1\n",
      "   1   1   1   1   2   1   1   2  87   1   1   1   1   1   1   1   5   4\n",
      "   1   1   1   1   1   1   1   1   1   1   1   1   1   2   1   3   1   1\n",
      "  16   3   1   1   1   3   1   1  44   2   1   1  11   1   1   1   2   1\n",
      "   1   1   1   1   4   2   1   1   1   2   1   1   1   1   1   1   1   1\n",
      " 105   1   1   5   3   1   2   5  22   2   4   1   1  18   5   1   8   2\n",
      "  19   1   2   1  65   2   6   4  69  26   4   4   5   8  19  19   9   6\n",
      "   5   5   4  21   4   4  14   5   4   4  25   4   6  28   4   6   6   7\n",
      "  23  48   4  21   4  12   4   5   5   5   5   8   4   1   1   1   1   1\n",
      "   2   3   2   1   1   1   2   1   1   2   1   1   1   7   4   1   1   2\n",
      "   1   3   2   2  14   1  11   4   2   3   1  10   2   1   1   1   1   1\n",
      "   1   1   1   1   1   1   1   2   1   1   2   1   1   1   7   2   1  23\n",
      "  51   1   2   1   1   1   1   2   1   6   1   1   1   1   1   1   1   3\n",
      "  67   2   1   1   1   2   1   1   1   1]\n"
     ]
    }
   ],
   "source": [
    "#lets consolidate everything we're working with\n",
    "u_users = unique_users[0:1000]\n",
    "print number_reviews_1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is a large population of user that write a large number of reviews. For our recommender system we can focus on the subset of the population that writes greater than $N$ reviews, so that there is more data upon which to base a recommender model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing a Rating Matrix\n",
    "- Define 0 to be unrated\n",
    "- 1 through 5 as usual\n",
    "\n",
    "We will focus on our subset of 1000 users but look at all products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74258"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256059"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['B004K2IHUO', 4],\n",
       "       ['B006L4FNB0', 4],\n",
       "       ['B00115FPV2', 5],\n",
       "       ['B009AVD282', 4],\n",
       "       ['B002Y1CVZU', 4],\n",
       "       ['B00815FR68', 4],\n",
       "       ['B000PKMN14', 4],\n",
       "       ['B006L4FMR0', 4]], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[reviews['UserId']==u_users[100]][['ProductId','Score']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def construct_rating_matrix(u_users,unique_products):\n",
    "    r_matrix = np.zeros((len(u_users),len(unique_products)))\n",
    "    for i in range(len(u_users)):\n",
    "        user = u_users[i]\n",
    "        products = reviews[reviews['UserId']== user][['ProductId','Score']].values\n",
    "        for j in range(len(products)):\n",
    "            product = products[j][0]\n",
    "            stars = products[j][1]\n",
    "            index = np.argwhere(unique_products == product)[0][0]\n",
    "            r_matrix[i,index] = stars\n",
    "    return r_matrix \n",
    "            \n",
    "rating_matrix = construct_rating_matrix(u_users,unique_products)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct User Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "#rating matrix to user similarity matrix \n",
    "def user_similarity_matrix(rating_matrix):\n",
    "    return 1 - pairwise_distances(rating_matrix, metric=\"cosine\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating predictions for a user $u$ requires using $s: U \\times U \\to R$, similarity function, to compute a neighborhood $ N \\subseteq U$ of neighbors of $U$\n",
    "\n",
    "#### Possible User/Product Similarity Functions:\n",
    "- Pearson Correlation: compute the statistical correlation between two vectors. This is the correlation as it is usually defined, sample covariance divided by the standard deviations.\n",
    "\n",
    "- Cosine similarity: similarity is measured as the cosine distance between two rating vectors. \n",
    "$$ \\frac{r_{u} \\cdot r_{v}}{||r_{u}|||r_{v}||}$$\n",
    "\n",
    "- Consider possibilities of other scoring methods \n",
    "\n",
    "#### Other Considerations: \n",
    "- Subtraction off the mean of each user to account for differences in users' use of the rating scale\n",
    "- Tuning parameter: number of group neighbors to select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's take users that have 10 or more ratings. We can tune this parameter later. Looking at the first 10000 users:..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "number_reviews_10000 = number_reviews(unique_users[0:10000])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u_users2 = unique_users[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1535,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_users2[number_reviews_10000>10].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we find that 1535 of the first 10000 users rated 10 items or more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#users who rated 10 or more\n",
    "users10 = u_users2[number_reviews_10000>10]\n",
    "\n",
    "#Construct rating matrix\n",
    "rating_matrix = construct_rating_matrix(users10,unique_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_matrix = user_similarity_matrix(rating_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  1.        ,  0.0720166 , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.0720166 ,  1.        , ...,  0.01864802,\n",
       "         0.        ,  0.        ],\n",
       "       ..., \n",
       "       [ 0.        ,  0.        ,  0.01864802, ...,  1.        ,\n",
       "         0.19083678,  0.17568633],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.19083678,\n",
       "         1.        ,  0.12258461],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.17568633,\n",
       "         0.12258461,  1.        ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the neighborhood $N \\subseteq U$ as the set of nearest neighbors to $u$ of size $N$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_nearest_users(user,cosine_similarities,users,N):\n",
    "    idx = np.argwhere(users == user)[0][0]\n",
    "    similar_indices = cosine_similarities[idx].argsort()[:-N-2:-1]\n",
    "    similar_users = [(cosine_similarities[idx][i], users[i],i) for i in similar_indices]\n",
    "    return similar_users[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.58140189973381107, 'A2725IB4YY9JEB', 0),\n",
       " (0.33921895875554398, 'A3SEW1ECTN5D0D', 592),\n",
       " (0.28997691150759519, 'A1CVQY61GRH0D5', 615),\n",
       " (0.27849211508082061, 'AJF5B70OO7S43', 593),\n",
       " (0.27198024059173842, 'A38AK9ROCL1UN6', 627),\n",
       " (0.26916754617306071, 'A221IYGUANAAL2', 617),\n",
       " (0.26916754617306071, 'A1YCWZWOXLUAY5', 614),\n",
       " (0.26676548700234215, 'A2BLJGGWN8GTXQ', 62)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test, gets the neighborhood of a user\n",
    "\n",
    "return_nearest_users('A2HL2BY512HTVQ',user_matrix,users10,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neighborhood = return_nearest_users('A2HL2BY512HTVQ',user_matrix,users10,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 5 Suggestions (User-User Collaborative Filtering):\n",
    "We make predictions according to:\n",
    "\n",
    "$$p_{u,i} = \\bar r_u + \\frac{\\sum{s(u,u')(r_{u',i} - \\bar r_{u'})}}{\\sum |s(u,u')|} $$\n",
    "\n",
    "Where the summation runs over all users in $N$. \n",
    "\n",
    "$\\bar r_{u'}$ is defined as the mean rating for user $u'$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#input: number of items to suggest N, neighborhood as defined above\n",
    "#we are assuming that the user is in the \n",
    "def suggest_items(user, N, neighborhood,users,rating_matrix):\n",
    "    \n",
    "    #mean rating for the user\n",
    "    idx = np.argwhere(users == user)[0][0]\n",
    "    mean_rating = rating_matrix[idx][rating_matrix[idx]!=0].mean()\n",
    "    \n",
    "    #from the neighborhood we get the simiarilities, the indices, and the usernames\n",
    "    indices = [i[2] for i in neighborhood]\n",
    "    similarities = np.array([i[0] for i in neighborhood])\n",
    "    usernames = [i[1] for i in neighborhood]\n",
    "    \n",
    "    #we'll only look at the ratings that are in the neighborhood\n",
    "    ratings = rating_matrix[indices]\n",
    "    \n",
    "    #adding user means to an array\n",
    "    user_means = []\n",
    "    for i in range(len(ratings)):\n",
    "        user_means.append(ratings[i,:][ratings[i,:]!=0].mean())\n",
    "    \n",
    "    #put these user means in an array of the correct size and shape\n",
    "    user_means = np.array([user_means]*ratings.shape[1]).T\n",
    "    \n",
    "    #new array for adjusted ratings, same size as ratings\n",
    "    adjust_ratings = np.zeros((ratings.shape[0],ratings.shape[1]))\n",
    "    adjust_ratings[ratings > 0] = ratings[ratings> 0] - user_means[ratings>0]\n",
    "    \n",
    "    #weight by similarity\n",
    "    adjusted_ratings = similarities.reshape(len(similarities),1) * adjust_ratings\n",
    "    unnormalized_predictions = np.sum(adjusted_ratings,axis=0)\n",
    "    \n",
    "    #following the formula above\n",
    "    predictions = unnormalized_predictions/(sum(similarities)) + mean_rating\n",
    "    \n",
    "    #return the best rated items\n",
    "    predicted_indices = predictions.argsort()[:-N-1:-1]\n",
    "    final_prediction = [(predictions[i], i) for i in predicted_indices]\n",
    "    return final_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3.4965541613799926, 539),\n",
       " (3.4965541613799926, 31062),\n",
       " (3.4965541613799926, 74173),\n",
       " (3.4965541613799926, 55576),\n",
       " (3.4965541613799926, 44669),\n",
       " (3.1490603247306308, 63921),\n",
       " (3.1490603247306308, 60237),\n",
       " (3.109585031680199, 67063),\n",
       " (3.0393201408593873, 65735),\n",
       " (3.0393201408593873, 29898)]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = suggest_items('A2HL2BY512HTVQ', 10, neighborhood, users10, rating_matrix)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested Products:\n",
      "\n",
      "B005K4Q1VI\n",
      "B005K4Q4KG\n",
      "B005K4Q68Q\n",
      "B005K4Q1T0\n",
      "B0076MLL12\n",
      "B0013A0QXC\n",
      "B000UBD88A\n",
      "B004LLAYA0\n",
      "B001E4S8GO\n",
      "B000XZFZI4\n"
     ]
    }
   ],
   "source": [
    "print 'Suggested Products:'\n",
    "print \n",
    "\n",
    "for i,j in predictions:\n",
    "    print unique_products[j]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we evaluate recommender systems?\n",
    " \n",
    "- We want to look at users that write a lot of reviews, so that we can validate our model's predictions by dividing their reviews into two parts\n",
    "- Training/Test set: We build the recommender system upon the training set. For the users in the test set we divide into **query set** and **target set**. \n",
    "- The **query set** is fed into the recommender system and the function we want to maximize is the similarity score between the recommendations based on the query set and the **target set**\n",
    "\n",
    "\n",
    "- Alternatively, our cost function can simply be the difference between predicted rating based on neighbors and our current rating\n",
    "\n",
    "Goal: write a reasonable score function. Our first score function will be based on the above and we will use our item similarity metric from content based filtering as our distance metric for target v. test\n",
    "\n",
    "\n",
    "**Two types of item similarity**:\n",
    "\n",
    "- Distance between user vectors\n",
    "- Distance between bag of word histograms <-- use this for this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#begin by dividing our rating matrix into train and test\n",
    "rand_perm = np.random.permutation(len(users10))\n",
    "train = rand_perm[:len(rand_perm)/2]\n",
    "test = rand_perm[len(rand_perm)/2:]\n",
    "\n",
    "#build our content based recommender off of the training set\n",
    "train_users = users10[train]\n",
    "test_users = users10[test]\n",
    "\n",
    "#divide the test users into query and target\n",
    "def query_and_target(test_users,unique_products):\n",
    "    \n",
    "    r_matrix = np.zeros((len(test_users),len(unique_products)))\n",
    "    target_sets =[]\n",
    "    \n",
    "    for i in range(len(test_users)):\n",
    "        user = test_users[i]\n",
    "        products = reviews[reviews['UserId']== user][['ProductId','Score']].values\n",
    "        #query set goes into matrix form (half)\n",
    "        \n",
    "        target_set = []\n",
    "        for j in range(len(products)/2):\n",
    "            product = products[j][0]\n",
    "            stars = products[j][1]\n",
    "            index = np.argwhere(unique_products == product)[0][0]\n",
    "            r_matrix[i,index] = stars\n",
    "        \n",
    "        #collect a list of target items and ratings (half)\n",
    "        for j in range(len(products)/2,len(products)):\n",
    "            product = products[j][0]\n",
    "            stars =products[j][1]\n",
    "            target_set.append((product,stars))\n",
    "        target_sets.append(target_set)\n",
    "    \n",
    "    return r_matrix , target_sets\n",
    "\n",
    "rating_matrix, target_sets = query_and_target(test_users,unique_products)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to rewrite the cosine similarities functions ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_rating_matrix = construct_rating_matrix(train_users,unique_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cos_distance(test_item,training_rating_matrix):\n",
    "    cos_distances =[]\n",
    "    for i in range(len(training_rating_matrix)):\n",
    "        cos_distances.append(1- cosine(test_item,training_rating_matrix[i]))\n",
    "    return np.array(cos_distances)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neighbors(cos_distances, n_neighbors,train_users):\n",
    "    args = cos_distances.argsort()[:-n_neighbors-1:-1]\n",
    "    list_of_users = [(cos_distances[i],train_users[i],i) for i in args]\n",
    "    return list_of_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cos_distances = cos_distance(rating_matrix[0],training_rating_matrix)\n",
    "list_neighbors = neighbors(cos_distances,5,train_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we list the 5 nearest neighbors in the training set of the first guy in the test set:**\n",
    "- The index is their index in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.43660667251700946, 'A1PMWT1I668I15', 397),\n",
       " (0.38830274910474849, 'A3T5NSG7LMRY0A', 703),\n",
       " (0.30100073218739798, 'A1RF9YK4BK5TRH', 31),\n",
       " (0.28223139320266732, 'A32GCOTGFJ9XC3', 463),\n",
       " (0.271696333500832, 'A1JFXOFDRZ9CFQ', 230)]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Suggest 5 Products based on these neighbors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def suggest_items(test_user,N, neighborhood,rating_matrix):\n",
    "    \n",
    "    mean_rating = test_user[test_user!=0].mean()\n",
    "    \n",
    "    #from the neighborhood we get the simiarilities, the indices, and the usernames\n",
    "    indices = [i[2] for i in neighborhood]\n",
    "    similarities = np.array([i[0] for i in neighborhood])\n",
    "    usernames = [i[1] for i in neighborhood]\n",
    "    \n",
    "    #we'll only look at the ratings that are in the neighborhood\n",
    "    ratings = rating_matrix[indices]\n",
    "    \n",
    "    #adding user means to an array\n",
    "    user_means = []\n",
    "    for i in range(len(ratings)):\n",
    "        user_means.append(ratings[i,:][ratings[i,:]!=0].mean())\n",
    "    \n",
    "    #put these user means in an array of the correct size and shape\n",
    "    user_means = np.array([user_means]*ratings.shape[1]).T\n",
    "    \n",
    "    #new array for adjusted ratings, same size as ratings\n",
    "    adjust_ratings = np.zeros((ratings.shape[0],ratings.shape[1]))\n",
    "    adjust_ratings[ratings > 0] = ratings[ratings> 0] - user_means[ratings>0]\n",
    "    \n",
    "    #weight by similarity\n",
    "    adjusted_ratings = similarities.reshape(len(similarities),1) * adjust_ratings\n",
    "    unnormalized_predictions = np.sum(adjusted_ratings,axis=0)\n",
    "    \n",
    "    #following the formula above\n",
    "    predictions = unnormalized_predictions/(sum(similarities)) + mean_rating\n",
    "    predictions[test_user!=0] = 0 \n",
    "    \n",
    "    #return the best rated items\n",
    "    predicted_indices = predictions.argsort()[:-N-1:-1]\n",
    "    final_prediction = [(predictions[i], i) for i in predicted_indices]\n",
    "    return final_prediction\n",
    "\n",
    "\n",
    "#alternative method of suggesting items... \n",
    "def suggest_items2(user_mean_rating, N, neighborhood,rating_matrix):\n",
    "    \n",
    "    mean_rating = user_mean_rating\n",
    "    #from the neighborhood we get the simiarilities, the indices, and the usernames\n",
    "    indices = [i[2] for i in neighborhood]\n",
    "    similarities = np.array([i[0] for i in neighborhood])\n",
    "    usernames = [i[1] for i in neighborhood]\n",
    "    \n",
    "    #we'll only look at the ratings that are in the neighborhood\n",
    "    ratings = rating_matrix[indices]\n",
    "    \n",
    "    #weight by similarity\n",
    "    adjusted_ratings = similarities.reshape(len(similarities),1) * ratings\n",
    "    unnormalized_predictions = np.sum(adjusted_ratings,axis=0)\n",
    "    \n",
    "    #following the formula above\n",
    "    predictions = unnormalized_predictions/(sum(similarities))\n",
    "    \n",
    "    #return the best rated items\n",
    "    predicted_indices = predictions.argsort()[:-N-1:-1]\n",
    "    final_prediction = [(predictions[i], i) for i in predicted_indices]\n",
    "    return final_prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:31: DeprecationWarning: using a boolean instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "pred = suggest_items(rating_matrix[0].mean(),5,list_neighbors,training_rating_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.12365252917518949, 58949),\n",
       " (0.12365252917518949, 24775),\n",
       " (0.12365252917518949, 5845),\n",
       " (0.12365252917518949, 55259),\n",
       " (0.12365252917518949, 49399)]"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B001EQ5K9U'"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_products[56084]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#put this all into one function:\n",
    "\n",
    "rand_perm = np.random.permutation(len(users10))\n",
    "train = rand_perm[:len(rand_perm)/2]\n",
    "test = rand_perm[len(rand_perm)/2:]\n",
    "\n",
    "#build our content based recommender off of the training set\n",
    "train_users = users10[train]\n",
    "test_users = users10[test]\n",
    "\n",
    "test_rating_matrix, target_sets = query_and_target(test_users,unique_products)\n",
    "training_rating_matrix = construct_rating_matrix(train_users,unique_products)\n",
    "\n",
    "\n",
    "# INPUT: index in the test rating matrix\n",
    "# OUTPUT: predictions\n",
    "def fn(i):\n",
    "    cos_distances = cos_distance(test_rating_matrix[i],training_rating_matrix)\n",
    "    list_neighbors = neighbors(cos_distances,20,train_users)\n",
    "    pred = suggest_items(test_rating_matrix[i],5,list_neighbors,training_rating_matrix)\n",
    "    print test_rating_matrix[i][test_rating_matrix[i]!=0].mean()\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "for i in fn(388):\n",
    "    print i[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST USER #: 0\n",
      "TARGET SETS\n",
      "5 B000E8WIAS\n",
      "4 B006ACQY8Y\n",
      "5 B0014RK2F6\n",
      "4 B005RGZO2G\n",
      "4 B005HB4HHO\n",
      "2 B003GADBDO\n",
      "4 B0038NA3X0\n",
      "4 B005HB4HH4\n",
      "5 B004VLVOZO\n",
      "\n",
      "RECOMMENDATIONS\n",
      "4.44444444444\n",
      "4.60504332251 B000ED9LDU\n",
      "4.60191213147 B001E5E3IA\n",
      "4.59637665323 B001E5E06K\n",
      "4.59637665323 B000P4Y8E0\n",
      "4.59637665323 B001Z7AEW6\n",
      "\n",
      "TEST USER #: 1\n",
      "TARGET SETS\n",
      "5 B002CJO8T6\n",
      "3 B000ORY230\n",
      "5 B0018QIPS4\n",
      "3 B00139ZPKM\n",
      "5 B002E0S506\n",
      "4 B001CBCJGE\n",
      "5 B0018QNL3I\n",
      "3 B000VK33C6\n",
      "3 B001EO77FW\n",
      "3 B001EO77FC\n",
      "5 B0018QIQFG\n",
      "5 B000LKX8YE\n",
      "\n",
      "RECOMMENDATIONS\n",
      "4.5\n",
      "4.75932169044 B000KV7ZGQ\n",
      "4.75932169044 B004R8FKO2\n",
      "4.75932169044 B000FA38ZY\n",
      "4.75932169044 B004FEN3GK\n",
      "4.75932169044 B000KV61FC\n",
      "\n",
      "TEST USER #: 2\n",
      "TARGET SETS\n",
      "2 B0047726E0\n",
      "4 B004JJMWWM\n",
      "5 B002GWME4A\n",
      "5 B002RGU2G2\n",
      "5 B0029JHN46\n",
      "5 B0087FJ23Q\n",
      "5 B003U95F9Y\n",
      "5 B007RTR8A2\n",
      "3 B005HG9ESG\n",
      "5 B001EO5UZ6\n",
      "5 B000UBH9YE\n",
      "5 B000EM8TYS\n",
      "5 B001M0A6C4\n",
      "5 B0032GL19S\n",
      "5 B0040J01L0\n",
      "5 B000EM6PKI\n",
      "2 B000HJ7AIY\n",
      "5 B001VH91OW\n",
      "5 B002LVACWM\n",
      "5 B004UOA23M\n",
      "5 B001E5E0NI\n",
      "5 B000V17MLS\n",
      "5 B002IEVJRY\n",
      "5 B0041QCURU\n",
      "1 B001UKBDGY\n",
      "4 B000Q611U6\n",
      "4 B007JFMIWW\n",
      "4 B001BM9ZQG\n",
      "5 B002GQ3IDC\n",
      "3 B0041CIP3M\n",
      "1 B000SAPXN6\n",
      "5 B000V9CLH0\n",
      "4 B004E4HUMY\n",
      "5 B003760Z90\n",
      "5 B00032C8T6\n",
      "4 B001OCKIBY\n",
      "5 B000SAPXFO\n",
      "5 B001DYMG36\n",
      "3 B005HG9ERW\n",
      "5 B001AXZ7Q8\n",
      "2 B004JQTBII\n",
      "4 B0015MY6PC\n",
      "5 B0001EQN88\n",
      "5 B00248EE4O\n",
      "5 B0044CPA28\n",
      "3 B005HG9ET0\n",
      "5 B000YSTIL0\n",
      "4 B006W5WAL4\n",
      "5 B002GWMDLY\n",
      "4 B000Q5X8DK\n",
      "3 B001BDDT8K\n",
      "3 B006MONQMC\n",
      "5 B0041QGE1S\n",
      "5 B000OZFECU\n",
      "5 B001VNGMPM\n",
      "5 B007JT7AIA\n",
      "5 B000HJNAXI\n",
      "\n",
      "RECOMMENDATIONS\n",
      "4.31578947368\n",
      "4.5562317701 B00248EE4O\n",
      "4.5562317701 B000YSTIL0\n",
      "4.48758733757 B0041CIP3M\n",
      "4.4763919956 B001EO5U3I\n",
      "4.4763919956 B008J1HO4C\n",
      "\n",
      "TEST USER #: 3\n",
      "TARGET SETS\n",
      "5 B000FNEZGM\n",
      "5 B000FNEZG2\n",
      "2 B000FDBQFK\n",
      "3 B003DIIMLK\n",
      "3 B003XB5LMU\n",
      "5 B000CQ01IS\n",
      "5 B000G2UUDO\n",
      "5 B002DZIL24\n",
      "\n",
      "RECOMMENDATIONS\n",
      "4.625\n",
      "4.66913745443 B006Q7YG56\n",
      "4.66913745443 B000JIN1H2\n",
      "4.66913745443 B004O5XB9Y\n",
      "4.66913745443 B003FDG4K4\n",
      "4.66913745443 B001EO7E5U\n",
      "\n",
      "TEST USER #: 4\n",
      "TARGET SETS\n",
      "5 B000GJOROU\n",
      "4 B007QTQ95I\n",
      "4 B0029JW71K\n",
      "4 B0029JW6TS\n",
      "4 B0029JW7E2\n",
      "5 B001IA3RV0\n",
      "1 B005SJ1D36\n",
      "2 B003WGPB6C\n",
      "5 B000FYVKW8\n",
      "1 B000EUD4ZO\n",
      "1 B000EUF9E8\n",
      "4 B000FYVKVE\n",
      "4 B000FYVKVE\n",
      "3 B004D4WMUK\n",
      "4 B0029JW6LG\n",
      "4 B000IZQ2PE\n",
      "5 B000FZ0TCY\n",
      "5 B005J5CQGW\n",
      "4 B001G5J7XO\n",
      "4 B000NMCJV8\n",
      "5 B0000GIZR4\n",
      "3 B004D503FA\n",
      "\n",
      "RECOMMENDATIONS\n",
      "4.09090909091\n",
      "4.26507682522 B003KV7V1C\n",
      "4.26507682522 B003KV4LRO\n",
      "4.25534942707 B001IA3RV0\n",
      "4.21855927568 B001HN5Z4K\n",
      "4.20134420365 B001OCKIBY\n",
      "\n",
      "TEST USER #: 5\n",
      "TARGET SETS\n",
      "3 B003VXL0V6\n",
      "3 B003VXL0V6\n",
      "2 B003TC7WN4\n",
      "3 B003TC7WN4\n",
      "3 B003TC7WN4\n",
      "2 B006N3IE6A\n",
      "3 B006N3IE6A\n",
      "3 B006N3IE6A\n",
      "2 B004FGWU9O\n",
      "3 B004FGWU9O\n",
      "3 B004FGWU9O\n",
      "2 B003VXHGDM\n",
      "3 B003VXHGDM\n",
      "3 B003VXHGDM\n",
      "\n",
      "RECOMMENDATIONS\n",
      "3.16666666667\n",
      "3.42137728937 B003TC7WN4\n",
      "3.42137728937 B006N3IE6A\n",
      "3.42137728937 B003VXHGDM\n",
      "3.42137728937 B004FGWU9O\n",
      "3.20010760381 B004UGP9PG\n",
      "\n",
      "TEST USER #: 6\n",
      "TARGET SETS\n",
      "5 B0044QYG2E\n",
      "5 B001AHJ2FQ\n",
      "1 B003AYMGWI\n",
      "1 B003A7EHU4\n",
      "5 B0043GFKG6\n",
      "1 B0049OQJXA\n",
      "4 B000MNT1FU\n",
      "5 B00451U7T4\n",
      "5 B001GZ7SP8\n",
      "5 B001EO651Y\n",
      "5 B001ABOB8K\n",
      "2 B003TO9RSU\n",
      "5 B00248EE4O\n",
      "5 B001E4S8GO\n",
      "5 B001ULOTKU\n",
      "5 B000YSTIL0\n",
      "5 B001ELL260\n",
      "\n",
      "RECOMMENDATIONS\n",
      "4.35294117647\n",
      "4.59273063889 B001AHJ2FQ\n",
      "4.59273063889 B000YSTIL0\n",
      "4.59273063889 B00248EE4O\n",
      "4.51425982921 B001E5E1WS\n",
      "4.482818722 B0081XPTBS\n",
      "\n",
      "TEST USER #: 7\n",
      "TARGET SETS\n",
      "5 B003VXL0V6\n",
      "4 B009B0V8V0\n",
      "4 B0015XWN7E\n",
      "4 B009B0VBR6\n",
      "5 B003TC7WN4\n",
      "4 B003VXFK3U\n",
      "5 B006N3IE6A\n",
      "2 B0045P8UL2\n",
      "5 B004FGWU9O\n",
      "5 B005HUVI0E\n",
      "5 B003VXHGDM\n",
      "\n",
      "RECOMMENDATIONS\n",
      "4.45454545455\n",
      "4.6709632133 B003VXL0V6\n",
      "4.6709632133 B003TC7WN4\n",
      "4.6709632133 B003VXHGDM\n",
      "4.6709632133 B006N3IE6A\n",
      "4.6709632133 B004FGWU9O\n",
      "\n",
      "TEST USER #: 8\n",
      "TARGET SETS\n",
      "4 B001EO5Q64\n",
      "4 B000GZU7QQ\n",
      "3 B001EO67ZS\n",
      "4 B003ZU0SWC\n",
      "1 B000HDMUOE\n",
      "4 B002AUNLLS\n",
      "4 B0049YMAJ2\n",
      "5 B0036Z3ULM\n",
      "\n",
      "RECOMMENDATIONS\n",
      "3.28571428571\n",
      "3.51720467979 B002866FCG\n",
      "3.51720467979 B0013E7C0S\n",
      "3.51720467979 B000CPCPWO\n",
      "3.51720467979 B000KNB0OW\n",
      "3.51720467979 B000ED9L9E\n",
      "\n",
      "TEST USER #: 9\n",
      "TARGET SETS\n",
      "1 B0058AMYTC\n",
      "1 B0058AMY5G\n",
      "1 B000G6O2QG\n",
      "1 B000LKVD5U\n",
      "1 B006WYSFZK\n",
      "1 B004728MI4\n",
      "1 B001SAXPEO\n",
      "\n",
      "RECOMMENDATIONS\n",
      "1.0\n",
      "1.0 B001LR2CU2\n",
      "1.0 B0054TWMZ8\n",
      "1.0 B001I7D0DS\n",
      "1.0 B000NV9VQA\n",
      "1.0 B001ANVNWA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# looking at first 10 test items\n",
    "\n",
    "for i in range(10):\n",
    "    print \"TEST USER #: \" +  str(i)\n",
    "    print \"TARGET SETS\"\n",
    "    for j in target_sets[i]:\n",
    "        print j[1],j[0]\n",
    "    \n",
    "    print\n",
    "    print \"RECOMMENDATIONS\"\n",
    "    for k in fn(i):\n",
    "        print k[0],unique_products[k[1]]\n",
    "    print \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**problem: if the second term is 0, recommendations are just the first ones**\n",
    "\n",
    "Ways to deal with this:\n",
    "- suggest highly rated products\n",
    "- use suggest_items2\n",
    "- larger neighborhood\n",
    "\n",
    "**also it's possible to get nans if there are no similar users at all (really unlikely because this means that the user didn't rate any of the same items as anyone else)**\n",
    "\n",
    "**fixed** another problem: it's possible to recommend products the user already reviewed. need to add a check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a Scoring Function\n",
    "- Above, we printed recommendations alongside the actual target set. We'll consider ways of scoring how well these recommendations compare to the target set.\n",
    "- First, we need a metric for product similarity. One way to do this is to look at product metadata (text and summaries)\n",
    "- We fit TF-IDF Vectorizer above for the content based approach, so we can use that to vectorize our products here. We'll take cosine similarity of these vectors to get product similarity. \n",
    "- We should only consider things in the target set that are positively reviewed:\n",
    "\n",
    "**Def. Similarity score between Recommendations and Target Set** \n",
    "\n",
    "$$ F(\\phi,\\lambda) = \\frac{1}{|\\phi||\\lambda|} \\sum_i \\sum_j R(\\lambda_j) s(\\phi_i, \\lambda_j) $$\n",
    "\n",
    "where $\\lambda$ is the set of recommendations and $\\phi$ is the positively review (>3.5) target set. We weight by the rating in the target set (either 4 or 5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#takes a fitted vectorizer as input, two product names\n",
    "#Uses to_words which I wrote at the very top\n",
    "def product_similarity(product1,product2,tf):\n",
    "    words1 = to_words(product1)\n",
    "    words2 = to_words(product2)\n",
    "    \n",
    "    vector1 = tf.transform(words1).toarray()\n",
    "    vector1 = vector1.reshape(vector1.shape[1],)\n",
    "    vector2 = tf.transform(words2).toarray()\n",
    "    vector2 = vector2.reshape(vector2.shape[1],)\n",
    "    \n",
    "    return 1 - cosine(vector1,vector2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#takes in the output of fn as well as the target set\n",
    "\n",
    "def score(target_set, recommendations):\n",
    "    positive_target_set = []\n",
    "    for i in target_set:\n",
    "        if i[1] > 3.5:\n",
    "            positive_target_set.append([i[1],i[0]])\n",
    "    score = 0\n",
    "    \n",
    "    recommended_items = []\n",
    "    for k in recommendations:\n",
    "        recommended_items.append(unique_products[k[1]])\n",
    "    \n",
    "    len_target = len(positive_target_set)\n",
    "    len_rec = len(recommended_items) \n",
    "    \n",
    "    #if the target set has no positively reviewed items, there's no basis for comparison, we return -1 indicating\n",
    "    # that this should be ignored\n",
    "    \n",
    "    if len_target == 0:\n",
    "        return -1\n",
    "    \n",
    "    \n",
    "    for p in recommended_items:\n",
    "        for q in positive_target_set:\n",
    "            rating = q[0]\n",
    "            score += rating * product_similarity(p,q[1],tf)\n",
    "    \n",
    "    score = score/ float(len_target*len_rec)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.44444444444\n",
      "TEST USER #: 0\n",
      "TARGET SETS\n",
      "5 B000E8WIAS\n",
      "4 B006ACQY8Y\n",
      "5 B0014RK2F6\n",
      "4 B005RGZO2G\n",
      "4 B005HB4HHO\n",
      "2 B003GADBDO\n",
      "4 B0038NA3X0\n",
      "4 B005HB4HH4\n",
      "5 B004VLVOZO\n",
      "\n",
      "RECOMMENDATIONS\n",
      "4.60504332251 B000ED9LDU\n",
      "4.60191213147 B001E5E3IA\n",
      "4.59637665323 B001E5E06K\n",
      "4.59637665323 B000P4Y8E0\n",
      "4.59637665323 B001Z7AEW6\n",
      "\n",
      "Score: \n",
      "0.466400741953\n",
      "\n",
      "4.5\n",
      "TEST USER #: 1\n",
      "TARGET SETS\n",
      "5 B002CJO8T6\n",
      "3 B000ORY230\n",
      "5 B0018QIPS4\n",
      "3 B00139ZPKM\n",
      "5 B002E0S506\n",
      "4 B001CBCJGE\n",
      "5 B0018QNL3I\n",
      "3 B000VK33C6\n",
      "3 B001EO77FW\n",
      "3 B001EO77FC\n",
      "5 B0018QIQFG\n",
      "5 B000LKX8YE\n",
      "\n",
      "RECOMMENDATIONS\n",
      "4.75932169044 B000KV7ZGQ\n",
      "4.75932169044 B004R8FKO2\n",
      "4.75932169044 B000FA38ZY\n",
      "4.75932169044 B004FEN3GK\n",
      "4.75932169044 B000KV61FC\n",
      "\n",
      "Score: \n",
      "0.627759684542\n",
      "\n",
      "4.31578947368\n",
      "TEST USER #: 2\n",
      "TARGET SETS\n",
      "2 B0047726E0\n",
      "4 B004JJMWWM\n",
      "5 B002GWME4A\n",
      "5 B002RGU2G2\n",
      "5 B0029JHN46\n",
      "5 B0087FJ23Q\n",
      "5 B003U95F9Y\n",
      "5 B007RTR8A2\n",
      "3 B005HG9ESG\n",
      "5 B001EO5UZ6\n",
      "5 B000UBH9YE\n",
      "5 B000EM8TYS\n",
      "5 B001M0A6C4\n",
      "5 B0032GL19S\n",
      "5 B0040J01L0\n",
      "5 B000EM6PKI\n",
      "2 B000HJ7AIY\n",
      "5 B001VH91OW\n",
      "5 B002LVACWM\n",
      "5 B004UOA23M\n",
      "5 B001E5E0NI\n",
      "5 B000V17MLS\n",
      "5 B002IEVJRY\n",
      "5 B0041QCURU\n",
      "1 B001UKBDGY\n",
      "4 B000Q611U6\n",
      "4 B007JFMIWW\n",
      "4 B001BM9ZQG\n",
      "5 B002GQ3IDC\n",
      "3 B0041CIP3M\n",
      "1 B000SAPXN6\n",
      "5 B000V9CLH0\n",
      "4 B004E4HUMY\n",
      "5 B003760Z90\n",
      "5 B00032C8T6\n",
      "4 B001OCKIBY\n",
      "5 B000SAPXFO\n",
      "5 B001DYMG36\n",
      "3 B005HG9ERW\n",
      "5 B001AXZ7Q8\n",
      "2 B004JQTBII\n",
      "4 B0015MY6PC\n",
      "5 B0001EQN88\n",
      "5 B00248EE4O\n",
      "5 B0044CPA28\n",
      "3 B005HG9ET0\n",
      "5 B000YSTIL0\n",
      "4 B006W5WAL4\n",
      "5 B002GWMDLY\n",
      "4 B000Q5X8DK\n",
      "3 B001BDDT8K\n",
      "3 B006MONQMC\n",
      "5 B0041QGE1S\n",
      "5 B000OZFECU\n",
      "5 B001VNGMPM\n",
      "5 B007JT7AIA\n",
      "5 B000HJNAXI\n",
      "\n",
      "RECOMMENDATIONS\n",
      "4.5562317701 B00248EE4O\n",
      "4.5562317701 B000YSTIL0\n",
      "4.48758733757 B0041CIP3M\n",
      "4.4763919956 B001EO5U3I\n",
      "4.4763919956 B008J1HO4C\n",
      "\n",
      "Score: \n",
      "0.666932332276\n",
      "\n",
      "4.625\n",
      "TEST USER #: 3\n",
      "TARGET SETS\n",
      "5 B000FNEZGM\n",
      "5 B000FNEZG2\n",
      "2 B000FDBQFK\n",
      "3 B003DIIMLK\n",
      "3 B003XB5LMU\n",
      "5 B000CQ01IS\n",
      "5 B000G2UUDO\n",
      "5 B002DZIL24\n",
      "\n",
      "RECOMMENDATIONS\n",
      "4.66913745443 B006Q7YG56\n",
      "4.66913745443 B000JIN1H2\n",
      "4.66913745443 B004O5XB9Y\n",
      "4.66913745443 B003FDG4K4\n",
      "4.66913745443 B001EO7E5U\n",
      "\n",
      "Score: \n",
      "0.649407411108\n",
      "\n",
      "4.09090909091\n",
      "TEST USER #: 4\n",
      "TARGET SETS\n",
      "5 B000GJOROU\n",
      "4 B007QTQ95I\n",
      "4 B0029JW71K\n",
      "4 B0029JW6TS\n",
      "4 B0029JW7E2\n",
      "5 B001IA3RV0\n",
      "1 B005SJ1D36\n",
      "2 B003WGPB6C\n",
      "5 B000FYVKW8\n",
      "1 B000EUD4ZO\n",
      "1 B000EUF9E8\n",
      "4 B000FYVKVE\n",
      "4 B000FYVKVE\n",
      "3 B004D4WMUK\n",
      "4 B0029JW6LG\n",
      "4 B000IZQ2PE\n",
      "5 B000FZ0TCY\n",
      "5 B005J5CQGW\n",
      "4 B001G5J7XO\n",
      "4 B000NMCJV8\n",
      "5 B0000GIZR4\n",
      "3 B004D503FA\n",
      "\n",
      "RECOMMENDATIONS\n",
      "4.26507682522 B003KV7V1C\n",
      "4.26507682522 B003KV4LRO\n",
      "4.25534942707 B001IA3RV0\n",
      "4.21855927568 B001HN5Z4K\n",
      "4.20134420365 B001OCKIBY\n",
      "\n",
      "Score: \n",
      "0.924908123885\n",
      "\n",
      "3.16666666667\n",
      "TEST USER #: 5\n",
      "TARGET SETS\n",
      "3 B003VXL0V6\n",
      "3 B003VXL0V6\n",
      "2 B003TC7WN4\n",
      "3 B003TC7WN4\n",
      "3 B003TC7WN4\n",
      "2 B006N3IE6A\n",
      "3 B006N3IE6A\n",
      "3 B006N3IE6A\n",
      "2 B004FGWU9O\n",
      "3 B004FGWU9O\n",
      "3 B004FGWU9O\n",
      "2 B003VXHGDM\n",
      "3 B003VXHGDM\n",
      "3 B003VXHGDM\n",
      "\n",
      "RECOMMENDATIONS\n",
      "3.42137728937 B003TC7WN4\n",
      "3.42137728937 B006N3IE6A\n",
      "3.42137728937 B003VXHGDM\n",
      "3.42137728937 B004FGWU9O\n",
      "3.20010760381 B004UGP9PG\n",
      "\n",
      "Score: \n",
      "-1\n",
      "\n",
      "4.35294117647\n",
      "TEST USER #: 6\n",
      "TARGET SETS\n",
      "5 B0044QYG2E\n",
      "5 B001AHJ2FQ\n",
      "1 B003AYMGWI\n",
      "1 B003A7EHU4\n",
      "5 B0043GFKG6\n",
      "1 B0049OQJXA\n",
      "4 B000MNT1FU\n",
      "5 B00451U7T4\n",
      "5 B001GZ7SP8\n",
      "5 B001EO651Y\n",
      "5 B001ABOB8K\n",
      "2 B003TO9RSU\n",
      "5 B00248EE4O\n",
      "5 B001E4S8GO\n",
      "5 B001ULOTKU\n",
      "5 B000YSTIL0\n",
      "5 B001ELL260\n",
      "\n",
      "RECOMMENDATIONS\n",
      "4.59273063889 B001AHJ2FQ\n",
      "4.59273063889 B000YSTIL0\n",
      "4.59273063889 B00248EE4O\n",
      "4.51425982921 B001E5E1WS\n",
      "4.482818722 B0081XPTBS\n",
      "\n",
      "Score: \n",
      "1.30193093514\n",
      "\n",
      "4.45454545455\n",
      "TEST USER #: 7\n",
      "TARGET SETS\n",
      "5 B003VXL0V6\n",
      "4 B009B0V8V0\n",
      "4 B0015XWN7E\n",
      "4 B009B0VBR6\n",
      "5 B003TC7WN4\n",
      "4 B003VXFK3U\n",
      "5 B006N3IE6A\n",
      "2 B0045P8UL2\n",
      "5 B004FGWU9O\n",
      "5 B005HUVI0E\n",
      "5 B003VXHGDM\n",
      "\n",
      "RECOMMENDATIONS\n",
      "4.6709632133 B003VXL0V6\n",
      "4.6709632133 B003TC7WN4\n",
      "4.6709632133 B003VXHGDM\n",
      "4.6709632133 B006N3IE6A\n",
      "4.6709632133 B004FGWU9O\n",
      "\n",
      "Score: \n",
      "3.50334416025\n",
      "\n",
      "3.28571428571\n",
      "TEST USER #: 8\n",
      "TARGET SETS\n",
      "4 B001EO5Q64\n",
      "4 B000GZU7QQ\n",
      "3 B001EO67ZS\n",
      "4 B003ZU0SWC\n",
      "1 B000HDMUOE\n",
      "4 B002AUNLLS\n",
      "4 B0049YMAJ2\n",
      "5 B0036Z3ULM\n",
      "\n",
      "RECOMMENDATIONS\n",
      "3.51720467979 B002866FCG\n",
      "3.51720467979 B0013E7C0S\n",
      "3.51720467979 B000CPCPWO\n",
      "3.51720467979 B000KNB0OW\n",
      "3.51720467979 B000ED9L9E\n",
      "\n",
      "Score: \n",
      "0.374634629282\n",
      "\n",
      "1.0\n",
      "TEST USER #: 9\n",
      "TARGET SETS\n",
      "1 B0058AMYTC\n",
      "1 B0058AMY5G\n",
      "1 B000G6O2QG\n",
      "1 B000LKVD5U\n",
      "1 B006WYSFZK\n",
      "1 B004728MI4\n",
      "1 B001SAXPEO\n",
      "\n",
      "RECOMMENDATIONS\n",
      "1.0 B001LR2CU2\n",
      "1.0 B0054TWMZ8\n",
      "1.0 B001I7D0DS\n",
      "1.0 B000NV9VQA\n",
      "1.0 B001ANVNWA\n",
      "\n",
      "Score: \n",
      "-1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    a = fn(i)\n",
    "    \n",
    "    print \"TEST USER #: \" +  str(i)\n",
    "    print \"TARGET SETS\"\n",
    "    for j in target_sets[i]:\n",
    "        print j[1],j[0]\n",
    "    \n",
    "    print\n",
    "    print \"RECOMMENDATIONS\"\n",
    "    for k in a:\n",
    "        print k[0],unique_products[k[1]]\n",
    "    print \n",
    "    print \"Score: \"\n",
    "    print score(target_sets[i],a)\n",
    "    print "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: delete print statement from fn that prints average user score later. This is necessary for now to see which ones are just recommending the first ones** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Recommendation\n",
    "We consider combining several different recommender systems into one. Namely our content based recommender system that recommends based on item similarity and our user based collaborative filtering model ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
