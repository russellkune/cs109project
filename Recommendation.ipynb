{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression as LogReg\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.cluster.vq import vq,kmeans,whiten\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#functions \n",
    "#input: product ID\n",
    "#output: sparse vector based on vectorizer\n",
    "\n",
    "def to_vector(product_id):\n",
    "    temp = reviews[reviews.ProductId == product_id]\n",
    "    text = list(temp['Text'].values + ' ' + temp['Summary'].values)\n",
    "    new_string = np.array([''.join(text)]).reshape(1,)\n",
    "    return vectorizer.transform(new_string).toarray()\n",
    "\n",
    "def to_words(product_id):\n",
    "    temp = reviews[reviews.ProductId == product_id]\n",
    "    text = list(temp['Text'].astype(str).values + ' ' + temp['Summary'].astype(str).values)\n",
    "    return np.array([''.join(text)]).reshape(1,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Unique products and users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('Reviews.csv')\n",
    "unique_users = reviews.UserId.unique()\n",
    "unique_products = reviews.ProductId.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.4949069023\n"
     ]
    }
   ],
   "source": [
    "#whole thing takes a long time(>30minutes), use first 1000 products\n",
    "start = time.time()\n",
    "unique_prod_reviews = map(lambda x: to_words(x),unique_products[0:1000])\n",
    "end = time.time()\n",
    "print end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>[I have bought several of the Vitality canned ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>[Product arrived labeled as Jumbo Salted Peanu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>[This is a confection that has been around a f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>[If you are looking for the secret ingredient ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>[Great taffy at a great price.  There was a wi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ProductId                                               Text\n",
       "0  B001E4KFG0  [I have bought several of the Vitality canned ...\n",
       "1  B00813GRG4  [Product arrived labeled as Jumbo Salted Peanu...\n",
       "2  B000LQOCH0  [This is a confection that has been around a f...\n",
       "3  B000UA0QIQ  [If you are looking for the secret ingredient ...\n",
       "4  B006K2ZZ7K  [Great taffy at a great price.  There was a wi..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the first 5 entries of the product DF\n",
    "product_df = pd.DataFrame()\n",
    "product_df['ProductId'] = unique_products[0:1000]\n",
    "product_df['Text'] = unique_prod_reviews\n",
    "product_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array(unique_prod_reviews)\n",
    "a = a.reshape(len(a),)\n",
    "tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 3), min_df=0, stop_words='english')\n",
    "tfidf_matrix = tf.fit_transform(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00,   5.36110174e-03,   0.00000000e+00, ...,\n",
       "          8.28603989e-03,   5.19533133e-03,   5.02833995e-03],\n",
       "       [  5.36110174e-03,   1.00000000e+00,   0.00000000e+00, ...,\n",
       "          5.29899866e-03,   0.00000000e+00,   1.78627910e-03],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       ..., \n",
       "       [  8.28603989e-03,   5.29899866e-03,   0.00000000e+00, ...,\n",
       "          1.00000000e+00,   8.30201976e-03,   7.89411311e-04],\n",
       "       [  5.19533133e-03,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          8.30201976e-03,   1.00000000e+00,   4.70532436e-03],\n",
       "       [  5.02833995e-03,   1.78627910e-03,   0.00000000e+00, ...,\n",
       "          7.89411311e-04,   4.70532436e-03,   1.00000000e+00]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix.toarray()\n",
    "cosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "cosine_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#takes a product name in the unique products data and returns the 8 most similar products\n",
    "#input: Product ID, Product Dataframe, Similarity Matrix\n",
    "#output: Array of 8 nearest items in the database using cosine similarity\n",
    "\n",
    "def return_nearest(product,cosine_similarities,product_df):\n",
    "    idx = product_df[product_df.ProductId == product].index[0]\n",
    "    similar_indices = cosine_similarities[idx].argsort()[:-10:-1]\n",
    "    similar_items = [(cosine_similarities[idx][i], product_df['ProductId'][i]) for i in similar_indices]\n",
    "    return similar_items[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.060071873611170931, 'B000CMFMG8'),\n",
       " (0.052140838382313696, 'B0047LRBX2'),\n",
       " (0.043432096349825311, 'B001EO6BCC'),\n",
       " (0.037325003722012799, 'B000G6RPMY'),\n",
       " (0.026276191344016604, 'B001FA1L7U'),\n",
       " (0.025318462964514555, 'B004AVYUOW'),\n",
       " (0.025057186536542934, 'B001HOUGFC'),\n",
       " (0.023818763987623219, 'B000YT5DBS')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_nearest('B00813GRG4',cosine_similarities,product_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def number_reviews(users):\n",
    "    number_reviews_ = []\n",
    "    for user in users:\n",
    "        number_reviews_.append(reviews[reviews['UserId'] == user].values.shape[0])\n",
    "    return np.array(number_reviews_)\n",
    "        \n",
    "start = time.time()    \n",
    "number_reviews_1000 = number_reviews(unique_users[0:1000])\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1   1   3   3   2   1   2   1   2   4   4  12   2  20 201   1   2   1\n",
      "  49   2   1   2   2   4   2   3   2   1   1   1   2  17   4   1   4   3\n",
      "   1   2   6  10   1   1   6  88  12 133   1  14   3   2   2   9   2   2\n",
      "   2   1   1   1   3   1   1   1   1   1   1   1   2   2   3   5   1   3\n",
      "  21   1   4  13  16   1  17   1   1   3   2   4   1   1   2   1   1   1\n",
      "   1   1   2   1   1   9   1   1   1  12   8  18   8  11   7   7   2   4\n",
      " 389   2   4   4   4   4   4   1   1   8   5   5   4   4   9   4   6   4\n",
      "   1  10   1   1   1   3   3  15   3  10   1   1   1   1  75   6 256  27\n",
      "   1   1   1   2   4   2   1   1   1   5   1   5   3  47   4   1   1   1\n",
      "  15   1   4   1   1   3   3   3   1   2   1   2   9   7  33  23   1  22\n",
      "   1   7   1   3   1 140   1   1   1   1  49   1   3   8   1   2   1   1\n",
      "   2   1   3   1   1   1   1   1   1   9   1   1  10   2   8   1   1   3\n",
      "  59   1   2   1   3   2   1   2   9   1   1   1   1   1  99   1   1   4\n",
      "   8   1   6  42  10   1   2   1   1   2   5   1   1   1   1   5   2   1\n",
      "   1   4   2   1   1   4   1   2   1   1   1  11   1  29   1  11   1   1\n",
      "   1  68   1   1   1   1   1   2   1   1  10   2   4  48  44   1   1   1\n",
      "   2  25   2   1   6   1   1   2   1   2   1   2   1   4   2  38   1   3\n",
      "  21   2   3   2   1   3   1   1   1   1   1   2   1   1   1   1   8   1\n",
      "   2   2   1  16   2   1   1   1   2   2   1   1  19   1   1   1   1   1\n",
      "   1   1   1   1   2   1   1   1   1   1   1   2   4   1  28   1   4   3\n",
      "   7  14   1   1   3   3   2 448  96   2  10   7   3   1   1   1   2   1\n",
      "   1   1   1 114   1   1   3   1   7   5   3   1   8   1   6   6   4   3\n",
      " 123   1   2   1   7   1   3  42   1   4   1   1   1   1   1   3  12   1\n",
      "   2   6   6   6 107   4  44  49  16  32  17  15  16 111  16  61  28  43\n",
      "  17  16  36  17  27  14 105  39  18  48  14  20  14  14  14  14  16  14\n",
      "  14  14  14  14  41  14  60  14  30  25 178  14  15  22 162  14  34  27\n",
      "  14  14  14  15  38  14  14  14  22  14  25  72  14  36  14  15  16  15\n",
      "  16  15  19  14  14  14  14  43  14  14  30  15  14  23  29  23  28  14\n",
      "  14  61  14  15  22  18  37  40  16 105  14  36  14  16 162  40  14  15\n",
      "  19  21  14  15  14  14  94 110  16  30  14  14  14  17  16  15  20  30\n",
      "  14  16  14  26  21  17  17  14  14  14  73  14  14 125  16  14  14  49\n",
      "  14  15  14  15  14  92  14  16  82  18  14  14  14  16  26  14  75 176\n",
      "  98  16  14  14  14  15  14  14  17  14  14  15  39  14  16  83  14 155\n",
      "  15  19  21  31  15  14  27  14  14  22  29  63  35  22  14  14  14  14\n",
      "  63  14  16  14  18  14  15   2   2   1   2  13   1   1   3   1   1   4\n",
      "  23  52  15   1   1   1   6   3   3   1   1   3   4   1   3   2   8  10\n",
      "   2   2   1   1   8  12  19   9  15   8   9  10  10   9   8 151   8  12\n",
      " 114   9  17  12   8   8   8   9   8  11   8   8   8  14   8  11  16   8\n",
      "   8   8   8   8   9   8   8  24  21  38   8   8   8   8   8  14   8   8\n",
      "   1   1   2   2   1   1   1   1   1   1   2  21   1  13   2   1   1   1\n",
      "   2  12  20  42   2   1   1   1   1   1   4   5   1   1   1   1 104   1\n",
      "   5   5  16   5  13   5   1   2   8   1   1   1   1   1   1   2   1   3\n",
      "   2 118   2   2   2   2  29   2   2   1   1   1   1   2  17   2   3   1\n",
      "   1   1   1   1   2   1   1   2  87   1   1   1   1   1   1   1   5   4\n",
      "   1   1   1   1   1   1   1   1   1   1   1   1   1   2   1   3   1   1\n",
      "  16   3   1   1   1   3   1   1  44   2   1   1  11   1   1   1   2   1\n",
      "   1   1   1   1   4   2   1   1   1   2   1   1   1   1   1   1   1   1\n",
      " 105   1   1   5   3   1   2   5  22   2   4   1   1  18   5   1   8   2\n",
      "  19   1   2   1  65   2   6   4  69  26   4   4   5   8  19  19   9   6\n",
      "   5   5   4  21   4   4  14   5   4   4  25   4   6  28   4   6   6   7\n",
      "  23  48   4  21   4  12   4   5   5   5   5   8   4   1   1   1   1   1\n",
      "   2   3   2   1   1   1   2   1   1   2   1   1   1   7   4   1   1   2\n",
      "   1   3   2   2  14   1  11   4   2   3   1  10   2   1   1   1   1   1\n",
      "   1   1   1   1   1   1   1   2   1   1   2   1   1   1   7   2   1  23\n",
      "  51   1   2   1   1   1   1   2   1   6   1   1   1   1   1   1   1   3\n",
      "  67   2   1   1   1   2   1   1   1   1]\n"
     ]
    }
   ],
   "source": [
    "#lets consolidate everything we're working with\n",
    "u_users = unique_users[0:1000]\n",
    "print number_reviews_1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is a large population of user that write a large number of reviews. For our recommender system we can focus on the subset of the population that writes greater than $N$ reviews, so that there is more data upon which to base a recommender model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing a Rating Matrix\n",
    "- Define 0 to be unrated\n",
    "- 1 through 5 as usual\n",
    "\n",
    "We will focus on our subset of 1000 users but look at all products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74258"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256059"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['B004K2IHUO', 4],\n",
       "       ['B006L4FNB0', 4],\n",
       "       ['B00115FPV2', 5],\n",
       "       ['B009AVD282', 4],\n",
       "       ['B002Y1CVZU', 4],\n",
       "       ['B00815FR68', 4],\n",
       "       ['B000PKMN14', 4],\n",
       "       ['B006L4FMR0', 4]], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[reviews['UserId']==u_users[100]][['ProductId','Score']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def construct_rating_matrix(u_users,unique_products):\n",
    "    r_matrix = np.zeros((len(u_users),len(unique_products)))\n",
    "    for i in range(len(u_users)):\n",
    "        user = u_users[i]\n",
    "        products = reviews[reviews['UserId']== user][['ProductId','Score']].values\n",
    "        for j in range(len(products)):\n",
    "            product = products[j][0]\n",
    "            stars = products[j][1]\n",
    "            index = np.argwhere(unique_products == product)[0][0]\n",
    "            r_matrix[i,index] = stars\n",
    "    return r_matrix \n",
    "            \n",
    "rating_matrix = construct_rating_matrix(u_users,unique_products)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct User Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "#rating matrix to user similarity matrix \n",
    "def user_similarity_matrix(rating_matrix):\n",
    "    return 1 - pairwise_distances(rating_matrix, metric=\"cosine\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating predictions for a user $u$ requires using $s: U \\times U \\to R$, similarity function, to compute a neighborhood $ N \\subseteq U$ of neighbors of $U$\n",
    "\n",
    "#### Possible User/Product Similarity Functions:\n",
    "- Pearson Correlation: compute the statistical correlation between two vectors. This is the correlation as it is usually defined, sample covariance divided by the standard deviations.\n",
    "\n",
    "- Cosine similarity: similarity is measured as the cosine distance between two rating vectors. \n",
    "$$ \\frac{r_{u} \\cdot r_{v}}{||r_{u}|||r_{v}||}$$\n",
    "\n",
    "- Consider possibilities of other scoring methods \n",
    "\n",
    "#### Other Considerations: \n",
    "- Subtraction off the mean of each user to account for differences in users' use of the rating scale\n",
    "- Tuning parameter: number of group neighbors to select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's take users that have 10 or more ratings. We can tune this parameter later. Looking at the first 10000 users:..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "number_reviews_10000 = number_reviews(unique_users[0:10000])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u_users2 = unique_users[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1535,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_users2[number_reviews_10000>10].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we find that 1535 of the first 10000 users rated 10 items or more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#users who rated 10 or more\n",
    "users10 = u_users2[number_reviews_10000>10]\n",
    "\n",
    "#Construct rating matrix\n",
    "rating_matrix = construct_rating_matrix(users10,unique_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_matrix = user_similarity_matrix(rating_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  1.        ,  0.0720166 , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.0720166 ,  1.        , ...,  0.01864802,\n",
       "         0.        ,  0.        ],\n",
       "       ..., \n",
       "       [ 0.        ,  0.        ,  0.01864802, ...,  1.        ,\n",
       "         0.19083678,  0.17568633],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.19083678,\n",
       "         1.        ,  0.12258461],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.17568633,\n",
       "         0.12258461,  1.        ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the neighborhood $N \\subseteq U$ as the set of nearest neighbors to $u$ of size $N$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_nearest_users(user,cosine_similarities,users,N):\n",
    "    idx = np.argwhere(users == user)[0][0]\n",
    "    similar_indices = cosine_similarities[idx].argsort()[:-N-2:-1]\n",
    "    similar_users = [(cosine_similarities[idx][i], users[i],i) for i in similar_indices]\n",
    "    return similar_users[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.58140189973381107, 'A2725IB4YY9JEB', 0),\n",
       " (0.33921895875554398, 'A3SEW1ECTN5D0D', 592),\n",
       " (0.28997691150759519, 'A1CVQY61GRH0D5', 615),\n",
       " (0.27849211508082061, 'AJF5B70OO7S43', 593),\n",
       " (0.27198024059173842, 'A38AK9ROCL1UN6', 627),\n",
       " (0.26916754617306071, 'A221IYGUANAAL2', 617),\n",
       " (0.26916754617306071, 'A1YCWZWOXLUAY5', 614),\n",
       " (0.26676548700234215, 'A2BLJGGWN8GTXQ', 62)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test, gets the neighborhood of a user\n",
    "\n",
    "return_nearest_users('A2HL2BY512HTVQ',user_matrix,users10,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neighborhood = return_nearest_users('A2HL2BY512HTVQ',user_matrix,users10,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 5 Suggestions (User-User Collaborative Filtering):\n",
    "We make predictions according to:\n",
    "\n",
    "$$p_{u,i} = \\bar r_u + \\frac{\\sum{s(u,u')(r_{u',i} - \\bar r_{u'})}}{\\sum |s(u,u')|} $$\n",
    "\n",
    "Where the summation runs over all users in $N$. \n",
    "\n",
    "$\\bar r_{u'}$ is defined as the mean rating for user $u'$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#input: number of items to suggest N, neighborhood as defined above\n",
    "#we are assuming that the user is in the \n",
    "def suggest_items(user, N, neighborhood,users,rating_matrix):\n",
    "    \n",
    "    #mean rating for the user\n",
    "    idx = np.argwhere(users == user)[0][0]\n",
    "    mean_rating = rating_matrix[idx][rating_matrix[idx]!=0].mean()\n",
    "    \n",
    "    #from the neighborhood we get the simiarilities, the indices, and the usernames\n",
    "    indices = [i[2] for i in neighborhood]\n",
    "    similarities = np.array([i[0] for i in neighborhood])\n",
    "    usernames = [i[1] for i in neighborhood]\n",
    "    \n",
    "    #we'll only look at the ratings that are in the neighborhood\n",
    "    ratings = rating_matrix[indices]\n",
    "    \n",
    "    #adding user means to an array\n",
    "    user_means = []\n",
    "    for i in range(len(ratings)):\n",
    "        user_means.append(ratings[i,:][ratings[i,:]!=0].mean())\n",
    "    \n",
    "    #put these user means in an array of the correct size and shape\n",
    "    user_means = np.array([user_means]*ratings.shape[1]).T\n",
    "    \n",
    "    #new array for adjusted ratings, same size as ratings\n",
    "    adjust_ratings = np.zeros((ratings.shape[0],ratings.shape[1]))\n",
    "    adjust_ratings[ratings > 0] = ratings[ratings> 0] - user_means[ratings>0]\n",
    "    \n",
    "    #weight by similarity\n",
    "    adjusted_ratings = similarities.reshape(len(similarities),1) * adjust_ratings\n",
    "    unnormalized_predictions = np.sum(adjusted_ratings,axis=0)\n",
    "    \n",
    "    #following the formula above\n",
    "    predictions = unnormalized_predictions/(sum(similarities)) + mean_rating\n",
    "    \n",
    "    #return the best rated items\n",
    "    predicted_indices = predictions.argsort()[:-N-1:-1]\n",
    "    final_prediction = [(predictions[i], i) for i in predicted_indices]\n",
    "    return final_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3.4965541613799926, 539),\n",
       " (3.4965541613799926, 31062),\n",
       " (3.4965541613799926, 74173),\n",
       " (3.4965541613799926, 55576),\n",
       " (3.4965541613799926, 44669),\n",
       " (3.1490603247306308, 63921),\n",
       " (3.1490603247306308, 60237),\n",
       " (3.109585031680199, 67063),\n",
       " (3.0393201408593873, 65735),\n",
       " (3.0393201408593873, 29898)]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = suggest_items('A2HL2BY512HTVQ', 10, neighborhood, users10, rating_matrix)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested Products:\n",
      "\n",
      "B005K4Q1VI\n",
      "B005K4Q4KG\n",
      "B005K4Q68Q\n",
      "B005K4Q1T0\n",
      "B0076MLL12\n",
      "B0013A0QXC\n",
      "B000UBD88A\n",
      "B004LLAYA0\n",
      "B001E4S8GO\n",
      "B000XZFZI4\n"
     ]
    }
   ],
   "source": [
    "print 'Suggested Products:'\n",
    "print \n",
    "\n",
    "for i,j in predictions:\n",
    "    print unique_products[j]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we evaluate recommender systems?\n",
    " \n",
    "- We want to look at users that write a lot of reviews, so that we can validate our model's predictions by dividing their reviews into two parts\n",
    "- Training/Test set: We build the recommender system upon the training set. For the users in the test set we divide into **query set** and **target set**. \n",
    "- The **query set** is fed into the recommender system and the function we want to maximize is the similarity score between the recommendations based on the query set and the **target set**\n",
    "\n",
    "\n",
    "- Alternatively, our cost function can simply be the difference between predicted rating based on neighbors and our current rating\n",
    "\n",
    "Goal: write a reasonable score function. Our first score function will be based on the above and we will use our item similarity metric from content based filtering as our distance metric for target v. test\n",
    "\n",
    "\n",
    "**Two types of item similarity**:\n",
    "\n",
    "- Distance between user vectors\n",
    "- Distance between bag of word histograms <-- use this for this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#begin by dividing our rating matrix into train and test\n",
    "rand_perm = np.random.permutation(len(users10))\n",
    "train = rand_perm[:len(rand_perm)/2]\n",
    "test = rand_perm[len(rand_perm)/2:]\n",
    "\n",
    "#build our content based recommender off of the training set\n",
    "train_users = users10[train]\n",
    "test_users = users10[test]\n",
    "\n",
    "#divide the test users into query and target\n",
    "def query_and_target(test_users,unique_products):\n",
    "    \n",
    "    r_matrix = np.zeros((len(test_users),len(unique_products)))\n",
    "    target_sets =[]\n",
    "    \n",
    "    for i in range(len(test_users)):\n",
    "        user = test_users[i]\n",
    "        products = reviews[reviews['UserId']== user][['ProductId','Score']].values\n",
    "        #query set goes into matrix form (half)\n",
    "        \n",
    "        target_set = []\n",
    "        for j in range(len(products)/2):\n",
    "            product = products[j][0]\n",
    "            stars = products[j][1]\n",
    "            index = np.argwhere(unique_products == product)[0][0]\n",
    "            r_matrix[i,index] = stars\n",
    "        \n",
    "        #collect a list of target items and ratings (half)\n",
    "        for j in range(len(products)/2,len(products)):\n",
    "            product = products[j][0]\n",
    "            stars =products[j][1]\n",
    "            target_set.append((product,stars))\n",
    "        target_sets.append(target_set)\n",
    "    \n",
    "    return r_matrix , target_sets\n",
    "\n",
    "rating_matrix, target_sets = query_and_target(test_users,unique_products)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to rewrite the cosine similarities functions ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_rating_matrix = construct_rating_matrix(train_users,unique_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cos_distance(test_item,training_rating_matrix):\n",
    "    cos_distances =[]\n",
    "    for i in range(len(training_rating_matrix)):\n",
    "        cos_distances.append(1- cosine(test_item,training_rating_matrix[i]))\n",
    "    return np.array(cos_distances)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neighbors(cos_distances, n_neighbors,train_users):\n",
    "    args = cos_distances.argsort()[:-n_neighbors-1:-1]\n",
    "    list_of_users = [(cos_distances[i],train_users[i],i) for i in args]\n",
    "    return list_of_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cos_distances = cos_distance(rating_matrix[0],training_rating_matrix)\n",
    "list_neighbors = neighbors(cos_distances,5,train_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we list the 5 nearest neighbors in the training set of the first guy in the test set:**\n",
    "- The index is their index in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.43660667251700946, 'A1PMWT1I668I15', 397),\n",
       " (0.38830274910474849, 'A3T5NSG7LMRY0A', 703),\n",
       " (0.30100073218739798, 'A1RF9YK4BK5TRH', 31),\n",
       " (0.28223139320266732, 'A32GCOTGFJ9XC3', 463),\n",
       " (0.271696333500832, 'A1JFXOFDRZ9CFQ', 230)]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Suggest 5 Products based on these neighbors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def suggest_items(user_mean_rating, N, neighborhood,rating_matrix):\n",
    "    \n",
    "    mean_rating = user_mean_rating\n",
    "    #from the neighborhood we get the simiarilities, the indices, and the usernames\n",
    "    indices = [i[2] for i in neighborhood]\n",
    "    similarities = np.array([i[0] for i in neighborhood])\n",
    "    usernames = [i[1] for i in neighborhood]\n",
    "    \n",
    "    #we'll only look at the ratings that are in the neighborhood\n",
    "    ratings = rating_matrix[indices]\n",
    "    \n",
    "    #adding user means to an array\n",
    "    user_means = []\n",
    "    for i in range(len(ratings)):\n",
    "        user_means.append(ratings[i,:][ratings[i,:]!=0].mean())\n",
    "    \n",
    "    #put these user means in an array of the correct size and shape\n",
    "    user_means = np.array([user_means]*ratings.shape[1]).T\n",
    "    \n",
    "    #new array for adjusted ratings, same size as ratings\n",
    "    adjust_ratings = np.zeros((ratings.shape[0],ratings.shape[1]))\n",
    "    adjust_ratings[ratings > 0] = ratings[ratings> 0] - user_means[ratings>0]\n",
    "    \n",
    "    #weight by similarity\n",
    "    adjusted_ratings = similarities.reshape(len(similarities),1) * adjust_ratings\n",
    "    unnormalized_predictions = np.sum(adjusted_ratings,axis=0)\n",
    "    \n",
    "    #following the formula above\n",
    "    predictions = unnormalized_predictions/(sum(similarities)) + mean_rating\n",
    "    \n",
    "    #return the best rated items\n",
    "    predicted_indices = predictions.argsort()[:-N-1:-1]\n",
    "    final_prediction = [(predictions[i], i) for i in predicted_indices]\n",
    "    return final_prediction\n",
    "\n",
    "\n",
    "#alternative method of suggesting items... \n",
    "def suggest_items2(user_mean_rating, N, neighborhood,rating_matrix):\n",
    "    \n",
    "    mean_rating = user_mean_rating\n",
    "    #from the neighborhood we get the simiarilities, the indices, and the usernames\n",
    "    indices = [i[2] for i in neighborhood]\n",
    "    similarities = np.array([i[0] for i in neighborhood])\n",
    "    usernames = [i[1] for i in neighborhood]\n",
    "    \n",
    "    #we'll only look at the ratings that are in the neighborhood\n",
    "    ratings = rating_matrix[indices]\n",
    "    \n",
    "    #weight by similarity\n",
    "    adjusted_ratings = similarities.reshape(len(similarities),1) * ratings\n",
    "    unnormalized_predictions = np.sum(adjusted_ratings,axis=0)\n",
    "    \n",
    "    #following the formula above\n",
    "    predictions = unnormalized_predictions/(sum(similarities))\n",
    "    \n",
    "    #return the best rated items\n",
    "    predicted_indices = predictions.argsort()[:-N-1:-1]\n",
    "    final_prediction = [(predictions[i], i) for i in predicted_indices]\n",
    "    return final_prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = suggest_items(rating_matrix[0].mean(),5,list_neighbors,training_rating_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.49578438518087325, 5337),\n",
       " (0.18536831266706855, 56084),\n",
       " (0.1823814003107638, 7710),\n",
       " (0.17216277388965642, 8344),\n",
       " (0.17216277388965642, 39672)]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B001EQ5K9U'"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_products[56084]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#put this all into one function:\n",
    "\n",
    "rand_perm = np.random.permutation(len(users10))\n",
    "train = rand_perm[:len(rand_perm)/2]\n",
    "test = rand_perm[len(rand_perm)/2:]\n",
    "\n",
    "#build our content based recommender off of the training set\n",
    "train_users = users10[train]\n",
    "test_users = users10[test]\n",
    "\n",
    "test_rating_matrix, target_sets = query_and_target(test_users,unique_products)\n",
    "training_rating_matrix = construct_rating_matrix(train_users,unique_products)\n",
    "\n",
    "\n",
    "# INPUT: index in the test rating matrix\n",
    "# OUTPUT: predictions\n",
    "def fn(i):\n",
    "    cos_distances = cos_distance(test_rating_matrix[i],training_rating_matrix)\n",
    "    list_neighbors = neighbors(cos_distances,20,train_users)\n",
    "    pred = suggest_items(test_rating_matrix[i][test_rating_matrix[i]!=0].mean(),5,list_neighbors,training_rating_matrix)\n",
    "    print test_rating_matrix[i][test_rating_matrix[i]!=0].mean()\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.92857142857\n",
      "4.01723106267\n",
      "4.01723106267\n",
      "4.01723106267\n",
      "4.0034764826\n",
      "4.00041942513\n"
     ]
    }
   ],
   "source": [
    "for i in fn(388):\n",
    "    print i[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST USER #: 0\n",
      "TARGET SETS\n",
      "5 B003VXL0V6\n",
      "5 B003TC7WN4\n",
      "5 B003TC7WN4\n",
      "5 B006N3IE6A\n",
      "5 B006N3IE6A\n",
      "5 B004FGWU9O\n",
      "5 B004FGWU9O\n",
      "5 B003VXHGDM\n",
      "5 B003VXHGDM\n",
      "\n",
      "RECOMMENDATIONS\n",
      "5.0\n",
      "5.27342331408 B006N3IG4K\n",
      "5.27342331408 B004FGWU9O\n",
      "5.27342331408 B003VXFK44\n",
      "5.27342331408 B003VXL0V6\n",
      "5.27342331408 B003VXHGDM\n",
      "\n",
      "TEST USER #: 1\n",
      "TARGET SETS\n",
      "2 B0009YSD6U\n",
      "3 B0017WG180\n",
      "3 B000OIZIVY\n",
      "2 B0038M4DZ0\n",
      "2 B001M050CK\n",
      "5 B0036ZGSZC\n",
      "2 B002Z9EQPO\n",
      "5 B000SARHDK\n",
      "2 B001E50U32\n",
      "2 B002Z9EQQ8\n",
      "1 B001EQ4CS0\n",
      "\n",
      "RECOMMENDATIONS\n",
      "2.8\n",
      "3.04907894488 B002ANCDMS\n",
      "3.04907894488 B002C1URM6\n",
      "3.04907894488 B002C1Y5GU\n",
      "3.04907894488 B002ANCDRI\n",
      "3.04907894488 B003S9GWU2\n",
      "\n",
      "TEST USER #: 2\n",
      "TARGET SETS\n",
      "5 B0018CG5BC\n",
      "3 B005GYJUHE\n",
      "5 B000OH73FO\n",
      "5 B001D6A5ZA\n",
      "5 B004VLVLR0\n",
      "5 B003SBZC1U\n",
      "2 B0007OVY0Y\n",
      "2 B001CD0YWS\n",
      "5 B0018CEABE\n",
      "3 B000WV153I\n",
      "\n",
      "RECOMMENDATIONS\n",
      "4.55555555556\n",
      "5.60190288998 B000VK2WZA\n",
      "5.60190288998 B000VK6NDC\n",
      "5.15342156034 B0015PMZRU\n",
      "5.15342156034 B0019MP8CS\n",
      "5.15342156034 B000HBO134\n",
      "\n",
      "TEST USER #: 3\n",
      "TARGET SETS\n",
      "5 B0029NII3C\n",
      "5 B0029NGY4M\n",
      "5 B0029NLV8G\n",
      "4 B0029NVOEC\n",
      "2 B002PJAZ0E\n",
      "5 B0029NGX34\n",
      "4 B005M16UHY\n",
      "5 B001EO6140\n",
      "4 B0029NVNY8\n",
      "4 B0029NVMGC\n",
      "4 B0029O6UQI\n",
      "5 B001KJ7FOY\n",
      "5 B007NH4BVW\n",
      "1 B000MO8ROK\n",
      "\n",
      "RECOMMENDATIONS\n",
      "4.5\n",
      "5.13026645384 B003EML8PM\n",
      "5.13026645384 B003EM7J9Q\n",
      "4.75682271344 B000EHP62G\n",
      "4.6890786336 B003M5TG28\n",
      "4.6890786336 B009GHI5Q4\n",
      "\n",
      "TEST USER #: 4\n",
      "TARGET SETS\n",
      "5 B008RWUKXK\n",
      "5 B005IW4WFY\n",
      "5 B005IW4WFY\n",
      "5 B008RWUHA6\n",
      "5 B008RWUHA6\n",
      "4 B006BXUY2Y\n",
      "4 B004YGQPAK\n",
      "\n",
      "RECOMMENDATIONS\n",
      "4.16666666667\n",
      "4.38813752515 B008RWUKXK\n",
      "4.38813752515 B005IW4WFY\n",
      "4.38813752515 B008RWUHA6\n",
      "4.32811206074 B004FEN3GK\n",
      "4.30171208558 B000FA38ZY\n",
      "\n",
      "TEST USER #: 5\n",
      "TARGET SETS\n",
      "5 B001AHJ2FQ\n",
      "5 B006Q7YG56\n",
      "4 B002TSA91Q\n",
      "4 B002TSA91G\n",
      "4 B005VOONI0\n",
      "5 B006Q7YG24\n",
      "5 B003VXHGE6\n",
      "3 B005A1LJ04\n",
      "3 B005A1LINC\n",
      "4 B005VOOM5E\n",
      "5 B003VXL0V6\n",
      "4 B005VOOLXM\n",
      "4 B005VOONGM\n",
      "5 B006Q7YG2O\n",
      "4 B005VOONM6\n",
      "4 B005VOOL00\n",
      "5 B00248EE4O\n",
      "5 B003TC7WN4\n",
      "5 B006N3IE6A\n",
      "5 B004FGWU9O\n",
      "5 B005VUILWI\n",
      "5 B000YSTIL0\n",
      "5 B003VXHGDM\n",
      "5 B0054I4LTO\n",
      "\n",
      "RECOMMENDATIONS\n",
      "4.21739130435\n",
      "4.41754683242 B000YSRK7E\n",
      "4.41754683242 B000YSTIL0\n",
      "4.41754683242 B001AHJ2D8\n",
      "4.41754683242 B001AHJ2FQ\n",
      "4.41754683242 B00248EE4O\n",
      "\n",
      "TEST USER #: 6\n",
      "TARGET SETS\n",
      "5 B000F9Z1UK\n",
      "5 B0040PUR6S\n",
      "5 B0040PWW84\n",
      "5 B002ZJQQK2\n",
      "5 B000LL0RHE\n",
      "5 B001E52XGO\n",
      "5 B000ILLX3Y\n",
      "5 B000LKZLP8\n",
      "5 B0040Q0AWI\n",
      "5 B0025UA5OO\n",
      "5 B000SV5DKS\n",
      "5 B000F9XBIE\n",
      "\n",
      "RECOMMENDATIONS\n",
      "4.81818181818\n",
      "5.38483513226 B000LKVDO6\n",
      "4.95307492663 B000F9XBIE\n",
      "4.95307492663 B000SV5DKS\n",
      "4.95307492663 B002ZJSSEE\n",
      "4.95307492663 B000F9Z29U\n",
      "\n",
      "TEST USER #: 7\n",
      "TARGET SETS\n",
      "1 B000LLHQAA\n",
      "1 B0058AMYTC\n",
      "1 B0058AMY5G\n",
      "1 B000G6O2QG\n",
      "1 B000LKVD5U\n",
      "1 B007I7YZJK\n",
      "1 B00473TIV8\n",
      "1 B006WYSFZK\n",
      "1 B004728MI4\n",
      "1 B001SAXPEO\n",
      "5 B00275QA2S\n",
      "\n",
      "RECOMMENDATIONS\n",
      "2.09090909091\n",
      "2.09090909091 B001LR2CU2\n",
      "2.09090909091 B008S1TC5C\n",
      "2.09090909091 B00513BPYQ\n",
      "2.09090909091 B000K8V0EM\n",
      "2.09090909091 B003AHMCUG\n",
      "\n",
      "TEST USER #: 8\n",
      "TARGET SETS\n",
      "4 B001E5305C\n",
      "5 B003FCZP9Q\n",
      "4 B000EDBPO8\n",
      "2 B0029JHHXS\n",
      "4 B001F3DZXU\n",
      "4 B000UUMOK4\n",
      "3 B001BOE3UW\n",
      "4 B000JP0RUO\n",
      "3 B001GVIRYI\n",
      "4 B004OQJQ2O\n",
      "4 B008MMTG4Y\n",
      "\n",
      "RECOMMENDATIONS\n",
      "4.09090909091\n",
      "4.19457215571 B000NMJWZO\n",
      "4.17403008262 B000K8R578\n",
      "4.17403008262 B000GZYAT6\n",
      "4.17403008262 B000CQ01NS\n",
      "4.14258494338 B001E50X66\n",
      "\n",
      "TEST USER #: 9\n",
      "TARGET SETS\n",
      "5 B000GWLUGU\n",
      "5 B0013LYLHS\n",
      "5 B0083QJU5O\n",
      "5 B0013LYLIW\n",
      "5 B000H241DS\n",
      "5 B000GWLR72\n",
      "\n",
      "RECOMMENDATIONS\n",
      "5.0\n",
      "5.23776520115 B001EO5U3I\n",
      "5.23776520115 B008J1HO4C\n",
      "5.23776520115 B001CX58IS\n",
      "5.17238993333 B001EQ56DA\n",
      "5.17238993333 B000LKWSG8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# looking at first 10 test items\n",
    "\n",
    "for i in range(10):\n",
    "    print \"TEST USER #: \" +  str(i)\n",
    "    print \"TARGET SETS\"\n",
    "    for j in target_sets[i]:\n",
    "        print j[1],j[0]\n",
    "    \n",
    "    print\n",
    "    print \"RECOMMENDATIONS\"\n",
    "    for k in fn(i):\n",
    "        print k[0],unique_products[k[1]]\n",
    "    print \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**problem: if the second term is 0, recommendations are just the first ones**\n",
    "\n",
    "Ways to deal with this:\n",
    "- suggest highly rated products\n",
    "- use suggest_items2\n",
    "- larger neighborhood\n",
    "\n",
    "**also it's possible to get nans if there are no similar users at all (really unlikely because this means that the user didn't rate any of the same items as anyone else)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a Scoring Function\n",
    "- Above, we printed recommendations alongside the actual target set. We'll consider ways of scoring how well these recommendations compare to the target set.\n",
    "- First, we need a metric for product similarity. One way to do this is to look at product metadata (text and summaries)\n",
    "- We fit TF-IDF Vectorizer above for the content based approach, so we can use that to vectorize our products here. We'll take cosine similarity of these vectors to get product similarity. \n",
    "- We should only consider things in the target set that are positively reviewed:\n",
    "\n",
    "**Def. Similarity score between Recommendations and Target Set** \n",
    "\n",
    "$$ F(\\phi,\\lambda) = \\frac{1}{|\\phi||\\lambda|} \\sum_i \\sum_j R(\\lambda_j) s(\\phi_i, \\lambda_j) $$\n",
    "\n",
    "where $\\lambda$ is the set of recommendations and $\\phi$ is the positively review (>3.5) target set. We weight by the rating in the target set (either 4 or 5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#takes a fitted vectorizer as input, two product names\n",
    "#Uses to_words which I wrote at the very top\n",
    "def product_similarity(product1,product2,tf):\n",
    "    words1 = to_words(product1)\n",
    "    words2 = to_words(product2)\n",
    "    \n",
    "    vector1 = tf.transform(words1).toarray()\n",
    "    vector1 = vector1.reshape(vector1.shape[1],)\n",
    "    vector2 = tf.transform(words2).toarray()\n",
    "    vector2 = vector2.reshape(vector2.shape[1],)\n",
    "    \n",
    "    return 1 - cosine(vector1,vector2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#takes in the output of fn as well as the target set\n",
    "\n",
    "def score(target_set, recommendations):\n",
    "    positive_target_set = []\n",
    "    for i in target_set:\n",
    "        if i[1] > 3.5:\n",
    "            positive_target_set.append([i[1],i[0]])\n",
    "    score = 0\n",
    "    \n",
    "    recommended_items = []\n",
    "    for k in recommendations:\n",
    "        recommended_items.append(unique_products[k[1]])\n",
    "    \n",
    "    len_target = len(positive_target_set)\n",
    "    len_rec = len(recommended_items) \n",
    "    \n",
    "    #if the target set has no positively reviewed items, there's no basis for comparison, we return -1 indicating\n",
    "    # that this should be ignored\n",
    "    \n",
    "    if len_rec == 0:\n",
    "        return -1\n",
    "    \n",
    "    \n",
    "    for p in recommended_items:\n",
    "        for q in positive_target_set:\n",
    "            rating = q[0]\n",
    "            score += rating * product_similarity(p,q[1],tf)\n",
    "    \n",
    "    score = score/ float(len_target*len_rec)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST USER #: 0\n",
      "TARGET SETS\n",
      "5 B003VXL0V6\n",
      "5 B003TC7WN4\n",
      "5 B003TC7WN4\n",
      "5 B006N3IE6A\n",
      "5 B006N3IE6A\n",
      "5 B004FGWU9O\n",
      "5 B004FGWU9O\n",
      "5 B003VXHGDM\n",
      "5 B003VXHGDM\n",
      "\n",
      "RECOMMENDATIONS\n",
      "5.0\n",
      "5.27342331408 B006N3IG4K\n",
      "5.27342331408 B004FGWU9O\n",
      "5.27342331408 B003VXFK44\n",
      "5.27342331408 B003VXL0V6\n",
      "5.27342331408 B003VXHGDM\n",
      "\n",
      "Score: \n",
      "5.0\n",
      "5.0\n",
      "\n",
      "TEST USER #: 1\n",
      "TARGET SETS\n",
      "2 B0009YSD6U\n",
      "3 B0017WG180\n",
      "3 B000OIZIVY\n",
      "2 B0038M4DZ0\n",
      "2 B001M050CK\n",
      "5 B0036ZGSZC\n",
      "2 B002Z9EQPO\n",
      "5 B000SARHDK\n",
      "2 B001E50U32\n",
      "2 B002Z9EQQ8\n",
      "1 B001EQ4CS0\n",
      "\n",
      "RECOMMENDATIONS\n",
      "2.8\n",
      "3.04907894488 B002ANCDMS\n",
      "3.04907894488 B002C1URM6\n",
      "3.04907894488 B002C1Y5GU\n",
      "3.04907894488 B002ANCDRI\n",
      "3.04907894488 B003S9GWU2\n",
      "\n",
      "Score: \n",
      "2.8\n",
      "0.314482400238\n",
      "\n",
      "TEST USER #: 2\n",
      "TARGET SETS\n",
      "5 B0018CG5BC\n",
      "3 B005GYJUHE\n",
      "5 B000OH73FO\n",
      "5 B001D6A5ZA\n",
      "5 B004VLVLR0\n",
      "5 B003SBZC1U\n",
      "2 B0007OVY0Y\n",
      "2 B001CD0YWS\n",
      "5 B0018CEABE\n",
      "3 B000WV153I\n",
      "\n",
      "RECOMMENDATIONS\n",
      "4.55555555556\n",
      "5.60190288998 B000VK2WZA\n",
      "5.60190288998 B000VK6NDC\n",
      "5.15342156034 B0015PMZRU\n",
      "5.15342156034 B0019MP8CS\n",
      "5.15342156034 B000HBO134\n",
      "\n",
      "Score: \n",
      "4.55555555556\n",
      "0.441800887247\n",
      "\n",
      "TEST USER #: 3\n",
      "TARGET SETS\n",
      "5 B0029NII3C\n",
      "5 B0029NGY4M\n",
      "5 B0029NLV8G\n",
      "4 B0029NVOEC\n",
      "2 B002PJAZ0E\n",
      "5 B0029NGX34\n",
      "4 B005M16UHY\n",
      "5 B001EO6140\n",
      "4 B0029NVNY8\n",
      "4 B0029NVMGC\n",
      "4 B0029O6UQI\n",
      "5 B001KJ7FOY\n",
      "5 B007NH4BVW\n",
      "1 B000MO8ROK\n",
      "\n",
      "RECOMMENDATIONS\n",
      "4.5\n",
      "5.13026645384 B003EML8PM\n",
      "5.13026645384 B003EM7J9Q\n",
      "4.75682271344 B000EHP62G\n",
      "4.6890786336 B003M5TG28\n",
      "4.6890786336 B009GHI5Q4\n",
      "\n",
      "Score: \n",
      "4.5\n",
      "0.829469999313\n",
      "\n",
      "TEST USER #: 4\n",
      "TARGET SETS\n",
      "5 B008RWUKXK\n",
      "5 B005IW4WFY\n",
      "5 B005IW4WFY\n",
      "5 B008RWUHA6\n",
      "5 B008RWUHA6\n",
      "4 B006BXUY2Y\n",
      "4 B004YGQPAK\n",
      "\n",
      "RECOMMENDATIONS\n",
      "4.16666666667\n",
      "4.38813752515 B008RWUKXK\n",
      "4.38813752515 B005IW4WFY\n",
      "4.38813752515 B008RWUHA6\n",
      "4.32811206074 B004FEN3GK\n",
      "4.30171208558 B000FA38ZY\n",
      "\n",
      "Score: \n",
      "4.16666666667\n",
      "2.79049030914\n",
      "\n",
      "TEST USER #: 5\n",
      "TARGET SETS\n",
      "5 B001AHJ2FQ\n",
      "5 B006Q7YG56\n",
      "4 B002TSA91Q\n",
      "4 B002TSA91G\n",
      "4 B005VOONI0\n",
      "5 B006Q7YG24\n",
      "5 B003VXHGE6\n",
      "3 B005A1LJ04\n",
      "3 B005A1LINC\n",
      "4 B005VOOM5E\n",
      "5 B003VXL0V6\n",
      "4 B005VOOLXM\n",
      "4 B005VOONGM\n",
      "5 B006Q7YG2O\n",
      "4 B005VOONM6\n",
      "4 B005VOOL00\n",
      "5 B00248EE4O\n",
      "5 B003TC7WN4\n",
      "5 B006N3IE6A\n",
      "5 B004FGWU9O\n",
      "5 B005VUILWI\n",
      "5 B000YSTIL0\n",
      "5 B003VXHGDM\n",
      "5 B0054I4LTO\n",
      "\n",
      "RECOMMENDATIONS\n",
      "4.21739130435\n",
      "4.41754683242 B000YSRK7E\n",
      "4.41754683242 B000YSTIL0\n",
      "4.41754683242 B001AHJ2D8\n",
      "4.41754683242 B001AHJ2FQ\n",
      "4.41754683242 B00248EE4O\n",
      "\n",
      "Score: \n",
      "4.21739130435\n",
      "1.32039512023\n",
      "\n",
      "TEST USER #: 6\n",
      "TARGET SETS\n",
      "5 B000F9Z1UK\n",
      "5 B0040PUR6S\n",
      "5 B0040PWW84\n",
      "5 B002ZJQQK2\n",
      "5 B000LL0RHE\n",
      "5 B001E52XGO\n",
      "5 B000ILLX3Y\n",
      "5 B000LKZLP8\n",
      "5 B0040Q0AWI\n",
      "5 B0025UA5OO\n",
      "5 B000SV5DKS\n",
      "5 B000F9XBIE\n",
      "\n",
      "RECOMMENDATIONS\n",
      "4.81818181818\n",
      "5.38483513226 B000LKVDO6\n",
      "4.95307492663 B000F9XBIE\n",
      "4.95307492663 B000SV5DKS\n",
      "4.95307492663 B002ZJSSEE\n",
      "4.95307492663 B000F9Z29U\n",
      "\n",
      "Score: \n",
      "4.81818181818\n",
      "1.25548328548\n",
      "\n",
      "TEST USER #: 7\n",
      "TARGET SETS\n",
      "1 B000LLHQAA\n",
      "1 B0058AMYTC\n",
      "1 B0058AMY5G\n",
      "1 B000G6O2QG\n",
      "1 B000LKVD5U\n",
      "1 B007I7YZJK\n",
      "1 B00473TIV8\n",
      "1 B006WYSFZK\n",
      "1 B004728MI4\n",
      "1 B001SAXPEO\n",
      "5 B00275QA2S\n",
      "\n",
      "RECOMMENDATIONS\n",
      "2.09090909091\n",
      "2.09090909091 B001LR2CU2\n",
      "2.09090909091 B008S1TC5C\n",
      "2.09090909091 B00513BPYQ\n",
      "2.09090909091 B000K8V0EM\n",
      "2.09090909091 B003AHMCUG\n",
      "\n",
      "Score: \n",
      "2.09090909091\n",
      "0.0864460737135\n",
      "\n",
      "TEST USER #: 8\n",
      "TARGET SETS\n",
      "4 B001E5305C\n",
      "5 B003FCZP9Q\n",
      "4 B000EDBPO8\n",
      "2 B0029JHHXS\n",
      "4 B001F3DZXU\n",
      "4 B000UUMOK4\n",
      "3 B001BOE3UW\n",
      "4 B000JP0RUO\n",
      "3 B001GVIRYI\n",
      "4 B004OQJQ2O\n",
      "4 B008MMTG4Y\n",
      "\n",
      "RECOMMENDATIONS\n",
      "4.09090909091\n",
      "4.19457215571 B000NMJWZO\n",
      "4.17403008262 B000K8R578\n",
      "4.17403008262 B000GZYAT6\n",
      "4.17403008262 B000CQ01NS\n",
      "4.14258494338 B001E50X66\n",
      "\n",
      "Score: \n",
      "4.09090909091\n",
      "0.324097024438\n",
      "\n",
      "TEST USER #: 9\n",
      "TARGET SETS\n",
      "5 B000GWLUGU\n",
      "5 B0013LYLHS\n",
      "5 B0083QJU5O\n",
      "5 B0013LYLIW\n",
      "5 B000H241DS\n",
      "5 B000GWLR72\n",
      "\n",
      "RECOMMENDATIONS\n",
      "5.0\n",
      "5.23776520115 B001EO5U3I\n",
      "5.23776520115 B008J1HO4C\n",
      "5.23776520115 B001CX58IS\n",
      "5.17238993333 B001EQ56DA\n",
      "5.17238993333 B000LKWSG8\n",
      "\n",
      "Score: \n",
      "5.0\n",
      "0.596090359976\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print \"TEST USER #: \" +  str(i)\n",
    "    print \"TARGET SETS\"\n",
    "    for j in target_sets[i]:\n",
    "        print j[1],j[0]\n",
    "    \n",
    "    print\n",
    "    print \"RECOMMENDATIONS\"\n",
    "    for k in fn(i):\n",
    "        print k[0],unique_products[k[1]]\n",
    "    print \n",
    "    print \"Score: \"\n",
    "    print score(target_sets[i],fn(i))\n",
    "    print "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: delete print statement from fn that prints average user score later. This is necessary for now to see which ones are just recommending the first ones** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Recommendation\n",
    "We consider combining several different recommender systems into one. Namely our content based recommender system that recommends based on item similarity and our user based collaborative filtering model ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
