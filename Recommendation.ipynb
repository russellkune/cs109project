{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression as LogReg\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.cluster.vq import vq,kmeans,whiten\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#functions \n",
    "#input: product ID\n",
    "#output: sparse vector based on vectorizer\n",
    "\n",
    "def to_vector(product_id):\n",
    "    temp = reviews[reviews.ProductId == product_id]\n",
    "    text = list(temp['Text'].values + ' ' + temp['Summary'].values)\n",
    "    new_string = np.array([''.join(text)]).reshape(1,)\n",
    "    return vectorizer.transform(new_string).toarray()\n",
    "\n",
    "def to_words(product_id):\n",
    "    temp = reviews[reviews.ProductId == product_id]\n",
    "    text = list(temp['Text'].astype(str).values + ' ' + temp['Summary'].astype(str).values)\n",
    "    return np.array([''.join(text)]).reshape(1,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Unique products and users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('Reviews.csv')\n",
    "unique_users = reviews.UserId.unique()\n",
    "unique_products = reviews.ProductId.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.4949069023\n"
     ]
    }
   ],
   "source": [
    "#whole thing takes a long time(>30minutes), use first 1000 products\n",
    "start = time.time()\n",
    "unique_prod_reviews = map(lambda x: to_words(x),unique_products[0:1000])\n",
    "end = time.time()\n",
    "print end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>[I have bought several of the Vitality canned ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>[Product arrived labeled as Jumbo Salted Peanu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>[This is a confection that has been around a f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>[If you are looking for the secret ingredient ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>[Great taffy at a great price.  There was a wi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ProductId                                               Text\n",
       "0  B001E4KFG0  [I have bought several of the Vitality canned ...\n",
       "1  B00813GRG4  [Product arrived labeled as Jumbo Salted Peanu...\n",
       "2  B000LQOCH0  [This is a confection that has been around a f...\n",
       "3  B000UA0QIQ  [If you are looking for the secret ingredient ...\n",
       "4  B006K2ZZ7K  [Great taffy at a great price.  There was a wi..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the first 5 entries of the product DF\n",
    "product_df = pd.DataFrame()\n",
    "product_df['ProductId'] = unique_products[0:1000]\n",
    "product_df['Text'] = unique_prod_reviews\n",
    "product_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array(unique_prod_reviews)\n",
    "a = a.reshape(len(a),)\n",
    "tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 3), min_df=0, stop_words='english')\n",
    "tfidf_matrix = tf.fit_transform(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00,   5.36110174e-03,   0.00000000e+00, ...,\n",
       "          8.28603989e-03,   5.19533133e-03,   5.02833995e-03],\n",
       "       [  5.36110174e-03,   1.00000000e+00,   0.00000000e+00, ...,\n",
       "          5.29899866e-03,   0.00000000e+00,   1.78627910e-03],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       ..., \n",
       "       [  8.28603989e-03,   5.29899866e-03,   0.00000000e+00, ...,\n",
       "          1.00000000e+00,   8.30201976e-03,   7.89411311e-04],\n",
       "       [  5.19533133e-03,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          8.30201976e-03,   1.00000000e+00,   4.70532436e-03],\n",
       "       [  5.02833995e-03,   1.78627910e-03,   0.00000000e+00, ...,\n",
       "          7.89411311e-04,   4.70532436e-03,   1.00000000e+00]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix.toarray()\n",
    "cosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "cosine_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#takes a product name in the unique products data and returns the 8 most similar products\n",
    "#input: Product ID, Product Dataframe, Similarity Matrix\n",
    "#output: Array of 8 nearest items in the database using cosine similarity\n",
    "\n",
    "def return_nearest(product,cosine_similarities,product_df):\n",
    "    idx = product_df[product_df.ProductId == product].index[0]\n",
    "    similar_indices = cosine_similarities[idx].argsort()[:-10:-1]\n",
    "    similar_items = [(cosine_similarities[idx][i], product_df['ProductId'][i]) for i in similar_indices]\n",
    "    return similar_items[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.060071873611170931, 'B000CMFMG8'),\n",
       " (0.052140838382313696, 'B0047LRBX2'),\n",
       " (0.043432096349825311, 'B001EO6BCC'),\n",
       " (0.037325003722012799, 'B000G6RPMY'),\n",
       " (0.026276191344016604, 'B001FA1L7U'),\n",
       " (0.025318462964514555, 'B004AVYUOW'),\n",
       " (0.025057186536542934, 'B001HOUGFC'),\n",
       " (0.023818763987623219, 'B000YT5DBS')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_nearest('B00813GRG4',cosine_similarities,product_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def number_reviews(users):\n",
    "    number_reviews_ = []\n",
    "    for user in users:\n",
    "        number_reviews_.append(reviews[reviews['UserId'] == user].values.shape[0])\n",
    "    return np.array(number_reviews_)\n",
    "        \n",
    "start = time.time()    \n",
    "number_reviews_1000 = number_reviews(unique_users[0:1000])\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1   1   3   3   2   1   2   1   2   4   4  12   2  20 201   1   2   1\n",
      "  49   2   1   2   2   4   2   3   2   1   1   1   2  17   4   1   4   3\n",
      "   1   2   6  10   1   1   6  88  12 133   1  14   3   2   2   9   2   2\n",
      "   2   1   1   1   3   1   1   1   1   1   1   1   2   2   3   5   1   3\n",
      "  21   1   4  13  16   1  17   1   1   3   2   4   1   1   2   1   1   1\n",
      "   1   1   2   1   1   9   1   1   1  12   8  18   8  11   7   7   2   4\n",
      " 389   2   4   4   4   4   4   1   1   8   5   5   4   4   9   4   6   4\n",
      "   1  10   1   1   1   3   3  15   3  10   1   1   1   1  75   6 256  27\n",
      "   1   1   1   2   4   2   1   1   1   5   1   5   3  47   4   1   1   1\n",
      "  15   1   4   1   1   3   3   3   1   2   1   2   9   7  33  23   1  22\n",
      "   1   7   1   3   1 140   1   1   1   1  49   1   3   8   1   2   1   1\n",
      "   2   1   3   1   1   1   1   1   1   9   1   1  10   2   8   1   1   3\n",
      "  59   1   2   1   3   2   1   2   9   1   1   1   1   1  99   1   1   4\n",
      "   8   1   6  42  10   1   2   1   1   2   5   1   1   1   1   5   2   1\n",
      "   1   4   2   1   1   4   1   2   1   1   1  11   1  29   1  11   1   1\n",
      "   1  68   1   1   1   1   1   2   1   1  10   2   4  48  44   1   1   1\n",
      "   2  25   2   1   6   1   1   2   1   2   1   2   1   4   2  38   1   3\n",
      "  21   2   3   2   1   3   1   1   1   1   1   2   1   1   1   1   8   1\n",
      "   2   2   1  16   2   1   1   1   2   2   1   1  19   1   1   1   1   1\n",
      "   1   1   1   1   2   1   1   1   1   1   1   2   4   1  28   1   4   3\n",
      "   7  14   1   1   3   3   2 448  96   2  10   7   3   1   1   1   2   1\n",
      "   1   1   1 114   1   1   3   1   7   5   3   1   8   1   6   6   4   3\n",
      " 123   1   2   1   7   1   3  42   1   4   1   1   1   1   1   3  12   1\n",
      "   2   6   6   6 107   4  44  49  16  32  17  15  16 111  16  61  28  43\n",
      "  17  16  36  17  27  14 105  39  18  48  14  20  14  14  14  14  16  14\n",
      "  14  14  14  14  41  14  60  14  30  25 178  14  15  22 162  14  34  27\n",
      "  14  14  14  15  38  14  14  14  22  14  25  72  14  36  14  15  16  15\n",
      "  16  15  19  14  14  14  14  43  14  14  30  15  14  23  29  23  28  14\n",
      "  14  61  14  15  22  18  37  40  16 105  14  36  14  16 162  40  14  15\n",
      "  19  21  14  15  14  14  94 110  16  30  14  14  14  17  16  15  20  30\n",
      "  14  16  14  26  21  17  17  14  14  14  73  14  14 125  16  14  14  49\n",
      "  14  15  14  15  14  92  14  16  82  18  14  14  14  16  26  14  75 176\n",
      "  98  16  14  14  14  15  14  14  17  14  14  15  39  14  16  83  14 155\n",
      "  15  19  21  31  15  14  27  14  14  22  29  63  35  22  14  14  14  14\n",
      "  63  14  16  14  18  14  15   2   2   1   2  13   1   1   3   1   1   4\n",
      "  23  52  15   1   1   1   6   3   3   1   1   3   4   1   3   2   8  10\n",
      "   2   2   1   1   8  12  19   9  15   8   9  10  10   9   8 151   8  12\n",
      " 114   9  17  12   8   8   8   9   8  11   8   8   8  14   8  11  16   8\n",
      "   8   8   8   8   9   8   8  24  21  38   8   8   8   8   8  14   8   8\n",
      "   1   1   2   2   1   1   1   1   1   1   2  21   1  13   2   1   1   1\n",
      "   2  12  20  42   2   1   1   1   1   1   4   5   1   1   1   1 104   1\n",
      "   5   5  16   5  13   5   1   2   8   1   1   1   1   1   1   2   1   3\n",
      "   2 118   2   2   2   2  29   2   2   1   1   1   1   2  17   2   3   1\n",
      "   1   1   1   1   2   1   1   2  87   1   1   1   1   1   1   1   5   4\n",
      "   1   1   1   1   1   1   1   1   1   1   1   1   1   2   1   3   1   1\n",
      "  16   3   1   1   1   3   1   1  44   2   1   1  11   1   1   1   2   1\n",
      "   1   1   1   1   4   2   1   1   1   2   1   1   1   1   1   1   1   1\n",
      " 105   1   1   5   3   1   2   5  22   2   4   1   1  18   5   1   8   2\n",
      "  19   1   2   1  65   2   6   4  69  26   4   4   5   8  19  19   9   6\n",
      "   5   5   4  21   4   4  14   5   4   4  25   4   6  28   4   6   6   7\n",
      "  23  48   4  21   4  12   4   5   5   5   5   8   4   1   1   1   1   1\n",
      "   2   3   2   1   1   1   2   1   1   2   1   1   1   7   4   1   1   2\n",
      "   1   3   2   2  14   1  11   4   2   3   1  10   2   1   1   1   1   1\n",
      "   1   1   1   1   1   1   1   2   1   1   2   1   1   1   7   2   1  23\n",
      "  51   1   2   1   1   1   1   2   1   6   1   1   1   1   1   1   1   3\n",
      "  67   2   1   1   1   2   1   1   1   1]\n"
     ]
    }
   ],
   "source": [
    "#lets consolidate everything we're working with\n",
    "u_users = unique_users[0:1000]\n",
    "print number_reviews_1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is a large population of user that write a large number of reviews. For our recommender system we can focus on the subset of the population that writes greater than $N$ reviews, so that there is more data upon which to base a recommender model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing a Rating Matrix\n",
    "- Define 0 to be unrated\n",
    "- 1 through 5 as usual\n",
    "\n",
    "We will focus on our subset of 1000 users but look at all products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74258"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256059"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['B004K2IHUO', 4],\n",
       "       ['B006L4FNB0', 4],\n",
       "       ['B00115FPV2', 5],\n",
       "       ['B009AVD282', 4],\n",
       "       ['B002Y1CVZU', 4],\n",
       "       ['B00815FR68', 4],\n",
       "       ['B000PKMN14', 4],\n",
       "       ['B006L4FMR0', 4]], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[reviews['UserId']==u_users[100]][['ProductId','Score']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def construct_rating_matrix(u_users,unique_products):\n",
    "    r_matrix = np.zeros((len(u_users),len(unique_products)))\n",
    "    for i in range(len(u_users)):\n",
    "        user = u_users[i]\n",
    "        products = reviews[reviews['UserId']== user][['ProductId','Score']].values\n",
    "        for j in range(len(products)):\n",
    "            product = products[j][0]\n",
    "            stars = products[j][1]\n",
    "            index = np.argwhere(unique_products == product)[0][0]\n",
    "            r_matrix[i,index] = stars\n",
    "    return r_matrix \n",
    "            \n",
    "rating_matrix = construct_rating_matrix(u_users,unique_products)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct User Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "#rating matrix to user similarity matrix \n",
    "def user_similarity_matrix(rating_matrix):\n",
    "    return 1 - pairwise_distances(rating_matrix, metric=\"cosine\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YAY!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating predictions for a user $u$ requires using $s: U \\times U \\to R$, similarity function, to compute a neighborhood $ N \\subseteq U$ of neighbors of $U$\n",
    "\n",
    "#### Possible User/Product Similarity Functions:\n",
    "- Pearson Correlation: compute the statistical correlation between two vectors. This is the correlation as it is usually defined, sample covariance divided by the standard deviations.\n",
    "\n",
    "- Cosine similarity: similarity is measured as the cosine distance between two rating vectors. \n",
    "$$ \\frac{r_{u} \\cdot r_{v}}{||r_{u}|||r_{v}||}$$\n",
    "\n",
    "- Consider possibilities of other scoring methods \n",
    "\n",
    "#### Other Considerations: \n",
    "- Subtraction off the mean of each user to account for differences in users' use of the rating scale\n",
    "- Tuning parameter: number of group neighbors to select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's take users that have 10 or more ratings. We can tune this parameter later. Looking at the first 10000 users:..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "number_reviews_10000 = number_reviews(unique_users[0:10000])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u_users2 = unique_users[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1535,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_users2[number_reviews_10000>10].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we find that 1535 of the first 10000 users rated 10 items or more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#users who rated 10 or more\n",
    "users10 = u_users2[number_reviews_10000>10]\n",
    "\n",
    "#Construct rating matrix\n",
    "rating_matrix = construct_rating_matrix(users10,unique_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_matrix = user_similarity_matrix(rating_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  1.        ,  0.0720166 , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.0720166 ,  1.        , ...,  0.01864802,\n",
       "         0.        ,  0.        ],\n",
       "       ..., \n",
       "       [ 0.        ,  0.        ,  0.01864802, ...,  1.        ,\n",
       "         0.19083678,  0.17568633],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.19083678,\n",
       "         1.        ,  0.12258461],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.17568633,\n",
       "         0.12258461,  1.        ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the neighborhood $N \\subseteq U$ as the set of nearest neighbors to $u$ of size $N$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_nearest_users(user,cosine_similarities,users,N):\n",
    "    idx = np.argwhere(users == user)[0][0]\n",
    "    similar_indices = cosine_similarities[idx].argsort()[:-N-2:-1]\n",
    "    similar_users = [(cosine_similarities[idx][i], users[i],i) for i in similar_indices]\n",
    "    return similar_users[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.58140189973381107, 'A2725IB4YY9JEB', 0),\n",
       " (0.33921895875554398, 'A3SEW1ECTN5D0D', 592),\n",
       " (0.28997691150759519, 'A1CVQY61GRH0D5', 615),\n",
       " (0.27849211508082061, 'AJF5B70OO7S43', 593),\n",
       " (0.27198024059173842, 'A38AK9ROCL1UN6', 627),\n",
       " (0.26916754617306071, 'A221IYGUANAAL2', 617),\n",
       " (0.26916754617306071, 'A1YCWZWOXLUAY5', 614),\n",
       " (0.26676548700234215, 'A2BLJGGWN8GTXQ', 62)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test, gets the neighborhood of a user\n",
    "\n",
    "return_nearest_users('A2HL2BY512HTVQ',user_matrix,users10,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neighborhood = return_nearest_users('A2HL2BY512HTVQ',user_matrix,users10,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 5 Suggestions (User-User Collaborative Filtering):\n",
    "We make predictions according to:\n",
    "\n",
    "$$p_{u,i} = \\bar r_u + \\frac{\\sum{s(u,u')(r_{u',i} - \\bar r_{u'})}}{\\sum |s(u,u')|} $$\n",
    "\n",
    "Where the summation runs over all users in $N$. \n",
    "\n",
    "$\\bar r_{u'}$ is defined as the mean rating for user $u'$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#input: number of items to suggest N, neighborhood as defined above\n",
    "\n",
    "def suggest_items(user, N, neighborhood,users):\n",
    "    \n",
    "    #mean rating for the user\n",
    "    idx = np.argwhere(users == user)[0][0]\n",
    "    mean_rating = rating_matrix[idx][rating_matrix[idx]!=0].mean()\n",
    "    \n",
    "    #from the neighborhood we get the simiarilities, the indices, and the usernames\n",
    "    indices = [i[2] for i in neighborhood]\n",
    "    similarities = np.array([i[0] for i in neighborhood])\n",
    "    usernames = [i[1] for i in neighborhood]\n",
    "    \n",
    "    #we'll only look at the ratings that are in the neighborhood\n",
    "    ratings = rating_matrix[indices]\n",
    "    \n",
    "    #adding user means to an array\n",
    "    user_means = []\n",
    "    for i in range(len(ratings)):\n",
    "        user_means.append(ratings[i,:][ratings[i,:]!=0].mean())\n",
    "    \n",
    "    #put these user means in an array of the correct size and shape\n",
    "    user_means = np.array([user_means]*ratings.shape[1]).T\n",
    "    \n",
    "    #new array for adjusted ratings, same size as ratings\n",
    "    adjust_ratings = np.zeros((ratings.shape[0],ratings.shape[1]))\n",
    "    adjust_ratings[ratings > 0] = ratings[ratings> 0] - user_means[ratings>0]\n",
    "    \n",
    "    #weight by similarity\n",
    "    adjusted_ratings = similarities.reshape(len(similarities),1) * adjust_ratings\n",
    "    unnormalized_predictions = np.sum(adjusted_ratings,axis=0)\n",
    "    \n",
    "    #following the formula above\n",
    "    predictions = unnormalized_predictions/(sum(similarities)) + mean_rating\n",
    "    \n",
    "    #return the best rated items\n",
    "    predicted_indices = predictions.argsort()[:-N-1:-1]\n",
    "    final_prediction = [(predictions[i], i) for i in predicted_indices]\n",
    "    return final_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3.4965541613799926, 539),\n",
       " (3.4965541613799926, 31062),\n",
       " (3.4965541613799926, 74173),\n",
       " (3.4965541613799926, 55576),\n",
       " (3.4965541613799926, 44669),\n",
       " (3.1490603247306308, 63921),\n",
       " (3.1490603247306308, 60237),\n",
       " (3.109585031680199, 67063),\n",
       " (3.0393201408593873, 65735),\n",
       " (3.0393201408593873, 29898)]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = suggest_items('A2HL2BY512HTVQ', 10, neighborhood, users10)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B005K4Q1VI\n",
      "B005K4Q4KG\n",
      "B005K4Q68Q\n",
      "B005K4Q1T0\n",
      "B0076MLL12\n",
      "B0013A0QXC\n",
      "B000UBD88A\n",
      "B004LLAYA0\n",
      "B001E4S8GO\n",
      "B000XZFZI4\n"
     ]
    }
   ],
   "source": [
    "for i,j in predictions:\n",
    "    print unique_products[j]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (8,) (8,74258) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-04c29f19d8f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mratings\u001b[0m  \u001b[0;34m-\u001b[0m \u001b[0muser_means\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (8,) (8,74258) "
     ]
    }
   ],
   "source": [
    "x = (ratings  - user_means)\n",
    "np.array(range(8)) * x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested Products:\n",
      "\n",
      "B0076MLL12\n",
      "B005K4Q68Q\n",
      "B005K4Q4KG\n",
      "B005K4Q1T0\n",
      "B005K4Q1VI\n"
     ]
    }
   ],
   "source": [
    "print 'Suggested Products:'\n",
    "print \n",
    "for i in predictions:\n",
    "    print unique_products[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we evaluate recommender systems?\n",
    " \n",
    "- We want to look at users that write a lot of reviews, so that we can validate our model's predictions by dividing their reviews into two parts\n",
    "- Training/Test set: We build the recommender system upon the training set. For the users in the test set we divide into **query set** and **target set**. \n",
    "- The **query set** is fed into the recommender system and the function we want to maximize is the similarity score between the recommendations based on the query set and the **target set**\n",
    "\n",
    "\n",
    "- Alternatively, our cost function can simply be the difference between predicted rating based on neighbors and our current rating\n",
    "\n",
    "Goal: write a reasonable score function. Our first score function will be based on the above and we will use our item similarity metric from content based filtering as our distance metric for target v. test\n",
    "\n",
    "\n",
    "**Two types of item similarity**:\n",
    "\n",
    "- Distance between user vectors\n",
    "- Distance between bag of word histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(model, test):\n",
    "    query = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Recommendation\n",
    "We consider combining several different recommender systems into one. Namely our content based recommender system that recommends based on item similarity and our user based collaborative filtering model ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
