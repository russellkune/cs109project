{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression as LogReg\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.cluster.vq import vq,kmeans,whiten\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#functions \n",
    "#input: product ID\n",
    "#output: sparse vector based on vectorizer\n",
    "\n",
    "def to_vector(product_id):\n",
    "    temp = reviews[reviews.ProductId == product_id]\n",
    "    text = list(temp['Text'].values + ' ' + temp['Summary'].values)\n",
    "    new_string = np.array([''.join(text)]).reshape(1,)\n",
    "    return vectorizer.transform(new_string).toarray()\n",
    "\n",
    "def to_words(product_id):\n",
    "    temp = reviews[reviews.ProductId == product_id]\n",
    "    text = list(temp['Text'].astype(str).values + ' ' + temp['Summary'].astype(str).values)\n",
    "    return np.array([''.join(text)]).reshape(1,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Unique products and users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('Reviews.csv')\n",
    "unique_users = reviews.UserId.unique()\n",
    "unique_products = reviews.ProductId.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.6910879612\n"
     ]
    }
   ],
   "source": [
    "#whole thing takes a long time(>30minutes), use first 1000 products\n",
    "start = time.time()\n",
    "unique_prod_reviews = map(lambda x: to_words(x),unique_products[0:1000])\n",
    "end = time.time()\n",
    "print end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>[I have bought several of the Vitality canned ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>[Product arrived labeled as Jumbo Salted Peanu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>[This is a confection that has been around a f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>[If you are looking for the secret ingredient ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>[Great taffy at a great price.  There was a wi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ProductId                                               Text\n",
       "0  B001E4KFG0  [I have bought several of the Vitality canned ...\n",
       "1  B00813GRG4  [Product arrived labeled as Jumbo Salted Peanu...\n",
       "2  B000LQOCH0  [This is a confection that has been around a f...\n",
       "3  B000UA0QIQ  [If you are looking for the secret ingredient ...\n",
       "4  B006K2ZZ7K  [Great taffy at a great price.  There was a wi..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the first 5 entries of the product DF\n",
    "product_df = pd.DataFrame()\n",
    "product_df['ProductId'] = unique_products[0:1000]\n",
    "product_df['Text'] = unique_prod_reviews\n",
    "product_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array(unique_prod_reviews)\n",
    "a = a.reshape(len(a),)\n",
    "tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 3), min_df=0, stop_words='english')\n",
    "tfidf_matrix = tf.fit_transform(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00,   5.36110174e-03,   0.00000000e+00, ...,\n",
       "          8.28603989e-03,   5.19533133e-03,   5.02833995e-03],\n",
       "       [  5.36110174e-03,   1.00000000e+00,   0.00000000e+00, ...,\n",
       "          5.29899866e-03,   0.00000000e+00,   1.78627910e-03],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       ..., \n",
       "       [  8.28603989e-03,   5.29899866e-03,   0.00000000e+00, ...,\n",
       "          1.00000000e+00,   8.30201976e-03,   7.89411311e-04],\n",
       "       [  5.19533133e-03,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          8.30201976e-03,   1.00000000e+00,   4.70532436e-03],\n",
       "       [  5.02833995e-03,   1.78627910e-03,   0.00000000e+00, ...,\n",
       "          7.89411311e-04,   4.70532436e-03,   1.00000000e+00]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix.toarray()\n",
    "cosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "cosine_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#takes a product name in the unique products data and returns the 8 most similar products\n",
    "#input: Product ID, Product Dataframe, Similarity Matrix\n",
    "#output: Array of 8 nearest items in the database using cosine similarity\n",
    "\n",
    "def return_nearest(product,cosine_similarities,product_df):\n",
    "    idx = product_df[product_df.ProductId == product].index[0]\n",
    "    similar_indices = cosine_similarities[idx].argsort()[:-10:-1]\n",
    "    similar_items = [(cosine_similarities[idx][i], product_df['ProductId'][i]) for i in similar_indices]\n",
    "    return similar_items[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.060071873611170931, 'B000CMFMG8'),\n",
       " (0.052140838382313696, 'B0047LRBX2'),\n",
       " (0.043432096349825311, 'B001EO6BCC'),\n",
       " (0.037325003722012799, 'B000G6RPMY'),\n",
       " (0.026276191344016604, 'B001FA1L7U'),\n",
       " (0.025318462964514555, 'B004AVYUOW'),\n",
       " (0.025057186536542934, 'B001HOUGFC'),\n",
       " (0.023818763987623219, 'B000YT5DBS')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_nearest('B00813GRG4',cosine_similarities,product_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def number_reviews(users):\n",
    "    number_reviews_ = []\n",
    "    for user in users:\n",
    "        number_reviews_.append(reviews[reviews['UserId'] == user].values.shape[0])\n",
    "    return np.array(number_reviews_)\n",
    "        \n",
    "start = time.time()    \n",
    "number_reviews_1000 = number_reviews(unique_users[0:1000])\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1   1   3   3   2   1   2   1   2   4   4  12   2  20 201   1   2   1\n",
      "  49   2   1   2   2   4   2   3   2   1   1   1   2  17   4   1   4   3\n",
      "   1   2   6  10   1   1   6  88  12 133   1  14   3   2   2   9   2   2\n",
      "   2   1   1   1   3   1   1   1   1   1   1   1   2   2   3   5   1   3\n",
      "  21   1   4  13  16   1  17   1   1   3   2   4   1   1   2   1   1   1\n",
      "   1   1   2   1   1   9   1   1   1  12   8  18   8  11   7   7   2   4\n",
      " 389   2   4   4   4   4   4   1   1   8   5   5   4   4   9   4   6   4\n",
      "   1  10   1   1   1   3   3  15   3  10   1   1   1   1  75   6 256  27\n",
      "   1   1   1   2   4   2   1   1   1   5   1   5   3  47   4   1   1   1\n",
      "  15   1   4   1   1   3   3   3   1   2   1   2   9   7  33  23   1  22\n",
      "   1   7   1   3   1 140   1   1   1   1  49   1   3   8   1   2   1   1\n",
      "   2   1   3   1   1   1   1   1   1   9   1   1  10   2   8   1   1   3\n",
      "  59   1   2   1   3   2   1   2   9   1   1   1   1   1  99   1   1   4\n",
      "   8   1   6  42  10   1   2   1   1   2   5   1   1   1   1   5   2   1\n",
      "   1   4   2   1   1   4   1   2   1   1   1  11   1  29   1  11   1   1\n",
      "   1  68   1   1   1   1   1   2   1   1  10   2   4  48  44   1   1   1\n",
      "   2  25   2   1   6   1   1   2   1   2   1   2   1   4   2  38   1   3\n",
      "  21   2   3   2   1   3   1   1   1   1   1   2   1   1   1   1   8   1\n",
      "   2   2   1  16   2   1   1   1   2   2   1   1  19   1   1   1   1   1\n",
      "   1   1   1   1   2   1   1   1   1   1   1   2   4   1  28   1   4   3\n",
      "   7  14   1   1   3   3   2 448  96   2  10   7   3   1   1   1   2   1\n",
      "   1   1   1 114   1   1   3   1   7   5   3   1   8   1   6   6   4   3\n",
      " 123   1   2   1   7   1   3  42   1   4   1   1   1   1   1   3  12   1\n",
      "   2   6   6   6 107   4  44  49  16  32  17  15  16 111  16  61  28  43\n",
      "  17  16  36  17  27  14 105  39  18  48  14  20  14  14  14  14  16  14\n",
      "  14  14  14  14  41  14  60  14  30  25 178  14  15  22 162  14  34  27\n",
      "  14  14  14  15  38  14  14  14  22  14  25  72  14  36  14  15  16  15\n",
      "  16  15  19  14  14  14  14  43  14  14  30  15  14  23  29  23  28  14\n",
      "  14  61  14  15  22  18  37  40  16 105  14  36  14  16 162  40  14  15\n",
      "  19  21  14  15  14  14  94 110  16  30  14  14  14  17  16  15  20  30\n",
      "  14  16  14  26  21  17  17  14  14  14  73  14  14 125  16  14  14  49\n",
      "  14  15  14  15  14  92  14  16  82  18  14  14  14  16  26  14  75 176\n",
      "  98  16  14  14  14  15  14  14  17  14  14  15  39  14  16  83  14 155\n",
      "  15  19  21  31  15  14  27  14  14  22  29  63  35  22  14  14  14  14\n",
      "  63  14  16  14  18  14  15   2   2   1   2  13   1   1   3   1   1   4\n",
      "  23  52  15   1   1   1   6   3   3   1   1   3   4   1   3   2   8  10\n",
      "   2   2   1   1   8  12  19   9  15   8   9  10  10   9   8 151   8  12\n",
      " 114   9  17  12   8   8   8   9   8  11   8   8   8  14   8  11  16   8\n",
      "   8   8   8   8   9   8   8  24  21  38   8   8   8   8   8  14   8   8\n",
      "   1   1   2   2   1   1   1   1   1   1   2  21   1  13   2   1   1   1\n",
      "   2  12  20  42   2   1   1   1   1   1   4   5   1   1   1   1 104   1\n",
      "   5   5  16   5  13   5   1   2   8   1   1   1   1   1   1   2   1   3\n",
      "   2 118   2   2   2   2  29   2   2   1   1   1   1   2  17   2   3   1\n",
      "   1   1   1   1   2   1   1   2  87   1   1   1   1   1   1   1   5   4\n",
      "   1   1   1   1   1   1   1   1   1   1   1   1   1   2   1   3   1   1\n",
      "  16   3   1   1   1   3   1   1  44   2   1   1  11   1   1   1   2   1\n",
      "   1   1   1   1   4   2   1   1   1   2   1   1   1   1   1   1   1   1\n",
      " 105   1   1   5   3   1   2   5  22   2   4   1   1  18   5   1   8   2\n",
      "  19   1   2   1  65   2   6   4  69  26   4   4   5   8  19  19   9   6\n",
      "   5   5   4  21   4   4  14   5   4   4  25   4   6  28   4   6   6   7\n",
      "  23  48   4  21   4  12   4   5   5   5   5   8   4   1   1   1   1   1\n",
      "   2   3   2   1   1   1   2   1   1   2   1   1   1   7   4   1   1   2\n",
      "   1   3   2   2  14   1  11   4   2   3   1  10   2   1   1   1   1   1\n",
      "   1   1   1   1   1   1   1   2   1   1   2   1   1   1   7   2   1  23\n",
      "  51   1   2   1   1   1   1   2   1   6   1   1   1   1   1   1   1   3\n",
      "  67   2   1   1   1   2   1   1   1   1]\n"
     ]
    }
   ],
   "source": [
    "#lets consolidate everything we're working with\n",
    "u_users = unique_users[0:1000]\n",
    "print number_reviews_1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is a large population of user that write a large number of reviews. For our recommender system we can focus on the subset of the population that writes greater than $N$ reviews, so that there is more data upon which to base a recommender model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing a Rating Matrix\n",
    "- Define 0 to be unrated\n",
    "- 1 through 5 as usual\n",
    "\n",
    "We will focus on our subset of 1000 users but look at all products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74258"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256059"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['B004K2IHUO', 4],\n",
       "       ['B006L4FNB0', 4],\n",
       "       ['B00115FPV2', 5],\n",
       "       ['B009AVD282', 4],\n",
       "       ['B002Y1CVZU', 4],\n",
       "       ['B00815FR68', 4],\n",
       "       ['B000PKMN14', 4],\n",
       "       ['B006L4FMR0', 4]], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[reviews['UserId']==u_users[100]][['ProductId','Score']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def construct_rating_matrix(u_users,unique_products):\n",
    "    r_matrix = np.zeros((len(u_users),len(unique_products)))\n",
    "    for i in range(len(u_users)):\n",
    "        user = u_users[i]\n",
    "        products = reviews[reviews['UserId']== user][['ProductId','Score']].values\n",
    "        for j in range(len(products)):\n",
    "            product = products[j][0]\n",
    "            stars = products[j][1]\n",
    "            index = np.argwhere(unique_products == product)\n",
    "            r_matrix[i,index] = stars\n",
    "    return r_matrix \n",
    "            \n",
    "rating_matrix = construct_rating_matrix(u_users,unique_products)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YAY!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating predictions for a user $u$ requires using $s: U \\times U \\to R$, similarity function, to compute a neighborhood $ N \\subseteq U$ of neighbors of $U$\n",
    "\n",
    "#### Possible User/Product Similarity Functions:\n",
    "- Pearson Correlation: compute the statistical correlation between two vectors. This is the correlation as it is usually defined, sample covariance divided by the standard deviations.\n",
    "\n",
    "- Cosine similarity: similarity is measured as the cosine distance between two rating vectors. \n",
    "$$ \\frac{r_{u} \\cdot r_{v}}{||r_{u}|||r_{v}||}$$\n",
    "\n",
    "\n",
    "#### Other Considerations: \n",
    "- Subtraction off the mean of each user to account for differences in users' use of the rating scale\n",
    "- Tuning parameter: number of group neighbors to select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we evaluate recommender systems?\n",
    "- We want to look at users that write a lot of reviews, so that we can validate our model's predictions by dividing their reviews into two parts\n",
    "- Training/Test set: We build the recommender system upon the training set. For the users in the test set we divide into **query set** and **target set**. \n",
    "- The **query set** is fed into the recommender system and the function we want to maximize is the similarity score between the recommendations based on the query set and the **target set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
